{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weird-ai.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Dy7d-SUY9cE3",
        "C5BVbY-fFnop",
        "FI2NvlkoEOFr",
        "AUGgxJzjYOw1",
        "PJT9WydO8bZB",
        "wfh6KBPaJBRt",
        "0BoaMdQ1GSYP",
        "P2t9Cd4d8zif",
        "AMLdfSu2GfTA",
        "1FBRWK4vG2t7",
        "2iZiO7py_z6g",
        "JGQ_wrxeZ2sr",
        "fDpxL_XpKCiD",
        "hfTgvG7cRuDe"
      ],
      "machine_shape": "hm",
      "mount_file_id": "12g07FS2WkNctNy_bYb7a5ZNFAsJcN0dz",
      "authorship_tag": "ABX9TyOh16yOj8BHl+YseXNtzDKF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8057b6da0fc046b781704d10924f2802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b819f45670334c6f90d8cda75aa4b7ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ab02a36c66e4960abfb127a30f8fc72",
              "IPY_MODEL_bfee079c61824313ad3e1ec321825454"
            ]
          }
        },
        "b819f45670334c6f90d8cda75aa4b7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ab02a36c66e4960abfb127a30f8fc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d78cdb0302e4d32bc95a92267269f2a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33d5644645e24eabb8b92329da3236de"
          }
        },
        "bfee079c61824313ad3e1ec321825454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_779c006efb5e463ea5651c5df2e174ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90c730bed147496d8a3629bd87cff9ed"
          }
        },
        "9d78cdb0302e4d32bc95a92267269f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33d5644645e24eabb8b92329da3236de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "779c006efb5e463ea5651c5df2e174ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90c730bed147496d8a3629bd87cff9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88fdcace049246e3a17360e386956271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09dbc8ef2cf94d2cb57458d9274feab3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9119ebed68447c69f1ca7bdd464559b",
              "IPY_MODEL_c1fc0713496946a7aae03d9ca9ae79bd"
            ]
          }
        },
        "09dbc8ef2cf94d2cb57458d9274feab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9119ebed68447c69f1ca7bdd464559b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50777f756c1640778945694c1906a04c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21aa838693284bc0a189f4fc4f390536"
          }
        },
        "c1fc0713496946a7aae03d9ca9ae79bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcd6382126e74f58bd9ad483e7d3a984",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54a385de6cc64250a445c4821d43710e"
          }
        },
        "50777f756c1640778945694c1906a04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21aa838693284bc0a189f4fc4f390536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcd6382126e74f58bd9ad483e7d3a984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54a385de6cc64250a445c4821d43710e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ed327819ffb45f69bf7c1eb1ad14c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a87a7cb86dc244ce8e4416b87314fb9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2d9ab815035439ca7e148fab8c28067",
              "IPY_MODEL_13e43bc5ee35460f9be906f1e07eb72e"
            ]
          }
        },
        "a87a7cb86dc244ce8e4416b87314fb9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2d9ab815035439ca7e148fab8c28067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abc1286341ef46e8a87f0bfacd7bceb9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd328d7fabe84c6ab1d2a60b4f736ac6"
          }
        },
        "13e43bc5ee35460f9be906f1e07eb72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2aafadfa176a43db8c44c706fbe183ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:16&lt;00:00, 41.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bafb6152a3f4b85b3d0f800a55677dd"
          }
        },
        "abc1286341ef46e8a87f0bfacd7bceb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd328d7fabe84c6ab1d2a60b4f736ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2aafadfa176a43db8c44c706fbe183ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bafb6152a3f4b85b3d0f800a55677dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe1c493dc7824226826434def09b6ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8ad1c0483054b4caedf733a872f0384",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25ac9648dee94734a02487206b8c7a11",
              "IPY_MODEL_b6ebade1c0124d38a15dd2a4e09de4d7"
            ]
          }
        },
        "d8ad1c0483054b4caedf733a872f0384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25ac9648dee94734a02487206b8c7a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b50e5ae3b43a47fe947f37878857b50c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45de42eea75b463f8c3bda6e6754ccfb"
          }
        },
        "b6ebade1c0124d38a15dd2a4e09de4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cfb350ac58f849d0a7683df7b55fc3d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:10&lt;00:00, 50.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cff023a67644dc5b0e149a6a34c0e0a"
          }
        },
        "b50e5ae3b43a47fe947f37878857b50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45de42eea75b463f8c3bda6e6754ccfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfb350ac58f849d0a7683df7b55fc3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cff023a67644dc5b0e149a6a34c0e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68b50b92e41241e187ee1e4cb9da425f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_376625c70db9472f9bbbd9e7b55b49b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c275de4e48f84ca1be6be1277e01cf2f",
              "IPY_MODEL_cd15e53d3d034512aaaa30614ba1b167"
            ]
          }
        },
        "376625c70db9472f9bbbd9e7b55b49b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c275de4e48f84ca1be6be1277e01cf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c8fc494284b4b6697bedc2ba2ac7d73",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00683170ccb54e6cae8974d59e2bc2dd"
          }
        },
        "cd15e53d3d034512aaaa30614ba1b167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2db9a8561c44cdc8bcf044d9ae1329a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:01&lt;00:00, 659kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc88fbc26d204fe3a5b796f8bdd35db7"
          }
        },
        "8c8fc494284b4b6697bedc2ba2ac7d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00683170ccb54e6cae8974d59e2bc2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2db9a8561c44cdc8bcf044d9ae1329a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc88fbc26d204fe3a5b796f8bdd35db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f35ed1851e42d398894507bc4f1ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3df3c03c89c4c37945f8e6fecde4514",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49991112adb24f4a952d5793090e6b74",
              "IPY_MODEL_5c330a51c41e44bf814c5739164fe8eb"
            ]
          }
        },
        "f3df3c03c89c4c37945f8e6fecde4514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49991112adb24f4a952d5793090e6b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_555dcd3fa91d4090806b3b00a5241db0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_343c371cc74842a1b97cc4a212885e4d"
          }
        },
        "5c330a51c41e44bf814c5739164fe8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14439330b46944fd840d4b274d921bf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 761/761 [00:00&lt;00:00, 1.24kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a005b531dba40dab26fbe49b9d6b49c"
          }
        },
        "555dcd3fa91d4090806b3b00a5241db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "343c371cc74842a1b97cc4a212885e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14439330b46944fd840d4b274d921bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a005b531dba40dab26fbe49b9d6b49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4043bd5b0d40441a9403736bb32fdc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb0bce2e16984225bd94e94a1b347506",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1616bcf8a7854ac39c8d5c87d977ef4b",
              "IPY_MODEL_09ed7f5dd5634bf391c5c38c64fecb86"
            ]
          }
        },
        "eb0bce2e16984225bd94e94a1b347506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1616bcf8a7854ac39c8d5c87d977ef4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f61caef45ec14d4a89684dedb99ff1c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1441285815,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1441285815,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6148cdb1cf84143af77a20dd9c5038d"
          }
        },
        "09ed7f5dd5634bf391c5c38c64fecb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_909e12639ee94fe6a66ecc4169b5bdb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.44G/1.44G [00:43&lt;00:00, 33.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26f714b50c104adc9dd0bc1632ea0580"
          }
        },
        "f61caef45ec14d4a89684dedb99ff1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6148cdb1cf84143af77a20dd9c5038d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "909e12639ee94fe6a66ecc4169b5bdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26f714b50c104adc9dd0bc1632ea0580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markriedl/weirdai/blob/master/weird_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw3axI05TLQv",
        "colab_type": "text"
      },
      "source": [
        "# Weird A.I Yankovic\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/h6xaopym08o977t/weird_ai_logo.JPG?dl=1\" alt=\"Weird A.I. Yankovic logo\" width=\"200px\"/>\n",
        "\n",
        "Weird A.I. Yankovic is a neural network based lyric generation system. Given a syllable and rhyme scheme, it attempts to generate new lyrics that fit that scheme.\n",
        "\n",
        "The intended use is to generate new lyrics for existing songs by feeding in the syllable and rhyme scheme for the song and then some contextualization information.\n",
        "\n",
        "It does not sing or match the lyrics to the music. You have to do that yourself. To make that easier, there are routines at the end for creating a karaoke video.\n",
        "\n",
        "This system was developed by [Mark Riedl](https://eilab.gatech.edu/mark-riedl). The work was performed independently of the Georgia Institute of Technology and released under MIT License.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhMvYhue1Azi",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy7d-SUY9cE3",
        "colab_type": "text"
      },
      "source": [
        "## Install stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1rUxP0mjH4e",
        "colab_type": "code",
        "outputId": "9a9d0af7-903a-48cd-8e4b-b90099d3e3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!apt-get install festival espeak-ng\n",
        "!pip install phonemizer\n",
        "!pip install transformers\n",
        "!pip install pronouncing\n",
        "!pip install wordfreq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  alsa-utils espeak-ng-data festlex-cmu festlex-poslex festvox-kallpc16k\n",
            "  libespeak-ng1 libestools2.5 libfftw3-single3 libnewt0.52 libpcaudio0\n",
            "  libsonic0 sgml-base whiptail\n",
            "Suggested packages:\n",
            "  pidgin-festival festival-freebsoft-utils libfftw3-bin libfftw3-dev\n",
            "  sgml-base-doc\n",
            "The following NEW packages will be installed:\n",
            "  alsa-utils espeak-ng espeak-ng-data festival festlex-cmu festlex-poslex\n",
            "  festvox-kallpc16k libespeak-ng1 libestools2.5 libfftw3-single3 libnewt0.52\n",
            "  libpcaudio0 libsonic0 sgml-base whiptail\n",
            "0 upgraded, 15 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 12.1 MB of archives.\n",
            "After this operation, 37.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 sgml-base all 1.29 [12.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnewt0.52 amd64 0.52.20-1ubuntu1 [40.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 whiptail amd64 0.52.20-1ubuntu1 [16.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-single3 amd64 3.3.7-1 [764 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 alsa-utils amd64 1.1.3-1ubuntu1 [966 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcaudio0 amd64 1.0-1 [6,536 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsonic0 amd64 0.2.0-6 [13.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 espeak-ng-data amd64 1.49.2+dfsg-1 [3,469 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libespeak-ng1 amd64 1.49.2+dfsg-1 [187 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak-ng amd64 1.49.2+dfsg-1 [282 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libestools2.5 amd64 1:2.5.0-4 [889 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 festival amd64 1:2.5.0-1 [804 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/universe amd64 festlex-cmu all 2.4-1 [895 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 festlex-poslex all 2.4-1 [186 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 festvox-kallpc16k all 2.4-1 [3,614 kB]\n",
            "Fetched 12.1 MB in 1s (8,222 kB/s)\n",
            "Selecting previously unselected package sgml-base.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../00-sgml-base_1.29_all.deb ...\n",
            "Unpacking sgml-base (1.29) ...\n",
            "Selecting previously unselected package libnewt0.52:amd64.\n",
            "Preparing to unpack .../01-libnewt0.52_0.52.20-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnewt0.52:amd64 (0.52.20-1ubuntu1) ...\n",
            "Selecting previously unselected package whiptail.\n",
            "Preparing to unpack .../02-whiptail_0.52.20-1ubuntu1_amd64.deb ...\n",
            "Unpacking whiptail (0.52.20-1ubuntu1) ...\n",
            "Selecting previously unselected package libfftw3-single3:amd64.\n",
            "Preparing to unpack .../03-libfftw3-single3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package alsa-utils.\n",
            "Preparing to unpack .../04-alsa-utils_1.1.3-1ubuntu1_amd64.deb ...\n",
            "Unpacking alsa-utils (1.1.3-1ubuntu1) ...\n",
            "Selecting previously unselected package libpcaudio0.\n",
            "Preparing to unpack .../05-libpcaudio0_1.0-1_amd64.deb ...\n",
            "Unpacking libpcaudio0 (1.0-1) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../06-libsonic0_0.2.0-6_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-6) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../07-espeak-ng-data_1.49.2+dfsg-1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.49.2+dfsg-1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../08-libespeak-ng1_1.49.2+dfsg-1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.49.2+dfsg-1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../09-espeak-ng_1.49.2+dfsg-1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.49.2+dfsg-1) ...\n",
            "Selecting previously unselected package libestools2.5:amd64.\n",
            "Preparing to unpack .../10-libestools2.5_1%3a2.5.0-4_amd64.deb ...\n",
            "Unpacking libestools2.5:amd64 (1:2.5.0-4) ...\n",
            "Selecting previously unselected package festival.\n",
            "Preparing to unpack .../11-festival_1%3a2.5.0-1_amd64.deb ...\n",
            "Unpacking festival (1:2.5.0-1) ...\n",
            "Selecting previously unselected package festlex-cmu.\n",
            "Preparing to unpack .../12-festlex-cmu_2.4-1_all.deb ...\n",
            "Unpacking festlex-cmu (2.4-1) ...\n",
            "Selecting previously unselected package festlex-poslex.\n",
            "Preparing to unpack .../13-festlex-poslex_2.4-1_all.deb ...\n",
            "Unpacking festlex-poslex (2.4-1) ...\n",
            "Selecting previously unselected package festvox-kallpc16k.\n",
            "Preparing to unpack .../14-festvox-kallpc16k_2.4-1_all.deb ...\n",
            "Unpacking festvox-kallpc16k (2.4-1) ...\n",
            "Setting up libestools2.5:amd64 (1:2.5.0-4) ...\n",
            "Setting up sgml-base (1.29) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-6) ...\n",
            "Setting up libpcaudio0 (1.0-1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.49.2+dfsg-1) ...\n",
            "Setting up libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Setting up libnewt0.52:amd64 (0.52.20-1ubuntu1) ...\n",
            "update-alternatives: using /etc/newt/palette.ubuntu to provide /etc/newt/palette (newt-palette) in auto mode\n",
            "Setting up whiptail (0.52.20-1ubuntu1) ...\n",
            "Setting up alsa-utils (1.1.3-1ubuntu1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.49.2+dfsg-1) ...\n",
            "Setting up festival (1:2.5.0-1) ...\n",
            "Setting up espeak-ng (1.49.2+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for systemd (237-3ubuntu10.40) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for sgml-base (1.29) ...\n",
            "Setting up festlex-cmu (2.4-1) ...\n",
            "Setting up festlex-poslex (2.4-1) ...\n",
            "Setting up festvox-kallpc16k (2.4-1) ...\n",
            "Collecting phonemizer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/93/b24323b7b7d99d65c41188685f423c66b2e53d0fd959851ac224c2aa2bfb/phonemizer-2.2-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hCollecting segments\n",
            "  Downloading https://files.pythonhosted.org/packages/5b/a0/0c3fe64787745c39eb3f2f5f5f9ed8d008d9ef22e9d7f9f52f71ea4712f7/segments-2.1.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from phonemizer) (0.14.1)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.6/dist-packages (from phonemizer) (19.3.0)\n",
            "Collecting clldutils>=1.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/ec/76860c7c36e8f6683a6d5041ebda054f4c1deca1a8aac9ea3357105139f5/clldutils-3.5.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 8.2MB/s \n",
            "\u001b[?25hCollecting csvw>=1.5.6\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/b6/8fef6788b8f05b21424a17ae3881eff916d42e5c7e87f57a85d9d7abf0a1/csvw-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from segments->phonemizer) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (2.8.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (0.8.7)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hCollecting rfc3986\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from csvw>=1.5.6->segments->phonemizer) (3.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->clldutils>=1.7.3->segments->phonemizer) (1.12.0)\n",
            "Installing collected packages: colorlog, isodate, rfc3986, csvw, clldutils, segments, phonemizer\n",
            "Successfully installed clldutils-3.5.1 colorlog-4.1.0 csvw-1.7.0 isodate-0.6.0 phonemizer-2.2 rfc3986-1.4.0 segments-2.1.3\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bab18b53ae052002a20867cacd4a0f17e4235713db9ee3c120e13f4f36e65f3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0 transformers-2.9.1\n",
            "Collecting pronouncing\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/c6/9dc74a3ddca71c492e224116b6654592bfe5717b4a78582e4d9c3345d153/pronouncing-0.2.0.tar.gz\n",
            "Collecting cmudict>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/cf/4d24ac4f3ea5a57406a690ad7c07023c310185eac99adae7473c9ebdf550/cmudict-0.4.4-py2.py3-none-any.whl (938kB)\n",
            "\u001b[K     |████████████████████████████████| 942kB 5.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6223 sha256=498e2e7c3979e37646c9c25977e8a3955d1b968f2756a076df208e423f24b51d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/fd/e8/fb1a226f707c7e20dbed4c43f81b819d279ffd3b0e2f06ee13\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-0.4.4 pronouncing-0.2.0\n",
            "Collecting wordfreq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/24/a4c3d79335c2c35d84d1728614ff9115999f7218f30f73f29c81778accc7/wordfreq-2.3.2.tar.gz (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.6/dist-packages (from wordfreq) (1.0.0)\n",
            "Collecting langcodes>=2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/1d/9b5ad179234206ad52f863c314851db7a00f69770c51d40c12c7513e628f/langcodes-2.0.0.tar.gz (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from wordfreq) (2019.12.20)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 41.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordfreq, langcodes, marisa-trie\n",
            "  Building wheel for wordfreq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordfreq: filename=wordfreq-2.3.2-cp36-none-any.whl size=32817238 sha256=76d8c807962b76a5e83883baafbc8d91523b503baa65e565adfd0f2633b50ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/ba/84/ba6be76208bd2c2124b6586f7967fb87e9f9fb4b4827e5e2c9\n",
            "  Building wheel for langcodes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langcodes: filename=langcodes-2.0.0-cp36-none-any.whl size=5044047 sha256=156369d833be39f4a7d708516e3ddb3d700fa7c7d75f149f22cc43c392e126b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/11/90/c7bba8118f3674d75e1457537635266a12538cf622a4684bb2\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=861244 sha256=b2fe1aac1054333c4377964fba6dff09207320ad4e8de1167305ac16ab744e6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built wordfreq langcodes marisa-trie\n",
            "Installing collected packages: marisa-trie, langcodes, wordfreq\n",
            "Successfully installed langcodes-2.0.0 marisa-trie-0.7.5 wordfreq-2.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GRPR_pjmXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import pdb\n",
        "import re\n",
        "import os\n",
        "import copy\n",
        "from functools import reduce\n",
        "import string\n",
        "import random\n",
        "import shutil\n",
        "import functools\n",
        "from phonemizer.phonemize import phonemize\n",
        "from phonemizer.separator import Separator\n",
        "import pronouncing\n",
        "from wordfreq import word_frequency, top_n_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5BVbY-fFnop",
        "colab_type": "text"
      },
      "source": [
        "## Set Up File Paths\n",
        "\n",
        "This is going to work faster if you mount your Google Drive and create a directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdqUJvJoAxo1",
        "colab_type": "code",
        "outputId": "f93eac38-dd55-409a-881f-f3d8c4f08a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "### If you want to store rhyme dictionary and phone cache in your Google Drive\n",
        "### First mount your drive and create a \"weirdai\" directory\n",
        "### If false, will download the rhyme dictionary each time and recreate an empty phone cache each time\n",
        "MY_DRIVE = '/content/drive/My Drive'\n",
        "WEIRD_AI_PATH = os.path.join(MY_DRIVE, 'weirdai')\n",
        "NEAR_RHYME_DICT_FILENAME = 'near_rhymes20000'\n",
        "PHONE_CACHE_FILENAME = 'phone_cache'\n",
        "NEAR_RHYME_PATH = os.path.join('/content/', NEAR_RHYME_DICT_FILENAME)\n",
        "PHONE_CACHE_PATH = os.path.join('/content/', PHONE_CACHE_FILENAME)\n",
        "if not os.path.exists(MY_DRIVE):\n",
        "  print(\"Google Drive not mounted.\")\n",
        "elif not os.path.exists(WEIRD_AI_PATH):\n",
        "  try:\n",
        "    os.mkdir(WEIRD_AI_PATH)\n",
        "    print(\"Making new directory\", WEIRD_AI_PATH)\n",
        "  except:\n",
        "    print(\"Could not make cache directory in Google Drive.\")\n",
        "\n",
        "if os.path.exists(WEIRD_AI_PATH):\n",
        "  NEAR_RHYME_PATH = os.path.join(WEIRD_AI_PATH, NEAR_RHYME_DICT_FILENAME)\n",
        "  PHONE_CACHE_PATH = os.path.join(WEIRD_AI_PATH, PHONE_CACHE_FILENAME)\n",
        "  print(\"Setting near rhyme dictionary path to\", NEAR_RHYME_PATH)\n",
        "  print(\"Setting phoneme cache to\", PHONE_CACHE_PATH)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting near rhyme dictionary path to /content/drive/My Drive/weirdai/near_rhymes20000\n",
            "Setting phoneme cache to /content/drive/My Drive/weirdai/phone_cache\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI2NvlkoEOFr",
        "colab_type": "text"
      },
      "source": [
        "## Global Parameters\n",
        "\n",
        "Some global parameters you can play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6KUzGHRsSdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Top-k most frequent rhymes\n",
        "RHYME_K = 50                          \n",
        "# for top-k sampling of tokens from language models\n",
        "SAMPLE_K = 40                         \n",
        "# How many times to try a line\n",
        "NUM_TRIES = 6                         \n",
        "### Always pick the best scoring line?\n",
        "GREEDY_PICK_LINE = False\n",
        "### temperature for picking different possible options for lines. Set to 1 to be most permissive. \n",
        "### Set closer to zero to be more conservative and prefer the best scoring line more.\n",
        "PICK_LINE_TEMPERATURE = 0.1\n",
        "### Setting this too high can cause memory problems\n",
        "MAX_CONTEXT_LENGTH = 125"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKsQwCjX9hG5",
        "colab_type": "text"
      },
      "source": [
        "## Rhyme dectection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_cH8BD98FKO",
        "colab_type": "text"
      },
      "source": [
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWWwK6DPbURZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### These are legit letters\n",
        "STR_LETTERS = set(string.ascii_letters + string.digits)\n",
        "\n",
        "### Is a string a word?\n",
        "def is_word(str):\n",
        "  str_set = set(str)\n",
        "  return len(str) > 0 and str_set.issubset(STR_LETTERS)\n",
        "\n",
        "### Is a letter a vowel?\n",
        "def is_vowel(letter):\n",
        "  return letter in ['a', 'e', 'i', 'o', 'u', 'y']\n",
        "\n",
        "### Is a letter a consonant?\n",
        "def is_consonant(letter):\n",
        "  return not is_vowel(letter)\n",
        "\n",
        "### Is a phoneme a vowel sound?\n",
        "### Pass in a phoneme (get this from Phonetic.phones_list)\n",
        "def is_vowel_sound(phoneme):\n",
        "  return is_vowel(phoneme[0])# and (is_vowel(phoneme[-1]) or phoneme[-1] in ['h', 'x', 'y'])\n",
        "\n",
        "### Is a phoneme a consonant sound?\n",
        "### Pass in a phoneme (get this from Phonetic.phones_list)\n",
        "def is_consonant_sound(phoneme):\n",
        "  return not is_vowel_sound(phoneme)\n",
        "\n",
        "### Return the number of vowel phonemes in a phoneneme list.\n",
        "### Pass in a list of phonemes (get this from Phonetic.phones_list)\n",
        "def num_vowel_phones(phone_list):\n",
        "  count = 0\n",
        "  for ph in phone_list:\n",
        "    if is_vowel(ph[0]):\n",
        "      count = count + 1\n",
        "  return count\n",
        "\n",
        "### For whatever reason, the first call to phonemize crashes because the API call fails.\n",
        "### This calls phonemize() once with a burner word just to get it out of the system\n",
        "def test_phonemize():\n",
        "  word = 'foobar'\n",
        "  try:\n",
        "    festival = phonemize(word, separator=Separator(phone='.', syllable='|', word=' ')).strip()\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    espeak = phonemize(word, backend='espeak', with_stress=True, separator=Separator(phone='.', syllable='', word=' ')).strip()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "### Return the indicies of a character (ch) in a string (s)\n",
        "def find_char_indexes(s, ch):\n",
        "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
        "\n",
        "### Gets the phonemize API going\n",
        "test_phonemize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_KEiwRu8IfY",
        "colab_type": "text"
      },
      "source": [
        "Get Phonemes and syllables for words.\n",
        "\n",
        "A Phonetic object stores several phonetic variations for a given word and knows the number of syllables for the word.\n",
        "\n",
        "The Phonetic constructor is given the word.\n",
        "\n",
        "Getting phonetic information is slow, so it caches its results in ``PHONE_CACHE``, which should be saved to disk to speed up processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErE8Rd_SqZB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Store phoneme information here for fast lookup\n",
        "PHONE_CACHE = {}  # Store results in cache for faster lookup\n",
        "\n",
        "### Phonetic class\n",
        "### word: orignal word\n",
        "class Phonetic():\n",
        "  def __init__(self, word):\n",
        "    global PHONE_CACHE\n",
        "    self.word = word                  # Remember the word\n",
        "    festival = None                   # festival results\n",
        "    espeak = None                     # espeak results\n",
        "    # If the word is in cache, use those results\n",
        "    if word in PHONE_CACHE:\n",
        "      festival, espeak = PHONE_CACHE[word]\n",
        "    else:\n",
        "      # API calls\n",
        "      festival = phonemize(word, separator=Separator(phone='.', syllable='|', word=' ')).strip()\n",
        "      espeak = phonemize(word, backend='espeak', with_stress=True, separator=Separator(phone='.', syllable='', word=' ')).strip()\n",
        "      # Store the results\n",
        "      PHONE_CACHE[word] = (festival, espeak)\n",
        "    # List of syllables. Each syllable is a list of phones\n",
        "    self.syllables_with_phones = [syl[:-1].split('.') for syl in festival.split('|')[:-1]]\n",
        "    # Just the syllables in raw form\n",
        "    self.syllables = festival.replace('.', '')\n",
        "    # Just the syllables in list form\n",
        "    self.syllables_list = self.syllables.split('|')[:-1]\n",
        "    # Just the phones in raw form\n",
        "    self.phones = festival.replace('|', '')\n",
        "    # Just the phones in list form\n",
        "    self.phones_list = self.phones.split('.')[:-1]\n",
        "    self.major_stress = 0       # The major stresses phone (index)\n",
        "    self.minor_stresses = []    # List of minor stressed phones (list of indices)\n",
        "    # Compute the major stress\n",
        "    major_stress_char_idxs = find_char_indexes(espeak, 'ˈ')\n",
        "    if len(major_stress_char_idxs) > 0:\n",
        "      stress_idx = espeak[:major_stress_char_idxs[0]].count('.')\n",
        "      if stress_idx < len(self.phones_list):\n",
        "        self.major_stress = stress_idx\n",
        "      else:\n",
        "        # Find the next earliest vowel phone\n",
        "        for i in range(len(self.phones_list)):\n",
        "          if is_vowel_sound(self.phones_list[len(self.phones_list)-i-1]):\n",
        "            self.major_stress = len(self.phones_list) - i - 1\n",
        "            break\n",
        "    # compute the minor stresses      \n",
        "    minor_stress_char_idxs = find_char_indexes(espeak, 'ˌ')\n",
        "    if len(minor_stress_char_idxs) > 0:\n",
        "      for char_idx in minor_stress_char_idxs:\n",
        "        stress_idx = espeak[:char_idx].count('.')\n",
        "        if stress_idx < len(self.phones_list):\n",
        "          self.minor_stresses.append(stress_idx)\n",
        "        else:\n",
        "          # Find the next earliest vowel phone\n",
        "          for i in range(len(self.phones_list)):\n",
        "            if is_vowel_sound(self.phones_list[len(self.phones_list)-i-1]):\n",
        "              self.minor_stresses.append(len(self.phones_list)-i-1)\n",
        "              break\n",
        "      # all stressed phones (list of indices)\n",
        "    self.all_stresses = sorted([self.major_stress] + self.minor_stresses[:])\n",
        "\n",
        "  def num_phones(self):\n",
        "    return len(self.phones_list)\n",
        "\n",
        "  def num_syllables(self):\n",
        "    return len(self.syllables_list)\n",
        "\n",
        "  def get_num_vowels(self):\n",
        "    return num_vowel_phones(self.phones_list)\n",
        "\n",
        "  def get_nth_vowel_phone(self, n=0):\n",
        "    count = -1\n",
        "    for i, ph in enumerate(self.phones_list):\n",
        "      if is_vowel_sound(ph):\n",
        "        count = count + 1\n",
        "      if count == n:\n",
        "        return ph, i\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def get_syllable_of_nth_phone(self, n):\n",
        "    count = -1\n",
        "    for i, syl in enumerate(self.syllables_list):\n",
        "      for ph in syl:\n",
        "        count = count + 1\n",
        "        if count == n:\n",
        "          return i\n",
        "    return None\n",
        "\n",
        "### Save the phone cache to disk\n",
        "def save_phone_cache(cache, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    for key in list(cache.keys()):\n",
        "      festival, espeak = cache[key]\n",
        "      f.write(key + '\\t' + festival + '\\t' + espeak + '\\n')\n",
        "\n",
        "### Load the phone cache from disk\n",
        "def load_phone_cache(filename):\n",
        "  cache = {}\n",
        "  for line in open(filename, 'r'):\n",
        "    line = line.strip()\n",
        "    split_line = line.split('\\t')\n",
        "    if len(split_line) >= 3:\n",
        "      word, festival, espeak = split_line\n",
        "      cache[word] = (festival, espeak)\n",
        "  return cache\n",
        "\n",
        "def load_near_rhyme_dictionary(filename):\n",
        "  rhyme_dict = {}\n",
        "  for line in open(filename, 'r'):\n",
        "    line = line.split('\\t')\n",
        "    key = line[0].strip()\n",
        "    val = line[1].strip()\n",
        "    if key not in rhyme_dict:\n",
        "      rhyme_dict[key] = []\n",
        "    rhyme_dict[key].append(val)\n",
        "  return rhyme_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiLDLu1D8Lzx",
        "colab_type": "text"
      },
      "source": [
        "Detect perfect rhyme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK6w8bFqJOG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Return true if two words are perfect ryles of each other\n",
        "def perfect_rhyme(word1, word2):\n",
        "  phonetic1 = Phonetic(word1)\n",
        "  phonetic2 = Phonetic(word2)\n",
        "  stress1 = phonetic1.all_stresses[-1]\n",
        "  stress2 = phonetic2.all_stresses[-1]\n",
        "  if phonetic1.num_phones() - stress1 != phonetic2.num_phones() - stress2:\n",
        "    return False\n",
        "  for i in range(phonetic1.num_phones() - stress1):\n",
        "    phone1 = phonetic1.phones_list[i + stress1]\n",
        "    phone2 = phonetic2.phones_list[i + stress2]\n",
        "    if phone1 != phone2:\n",
        "      return False\n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-cZYGuy8Qg3",
        "colab_type": "text"
      },
      "source": [
        "Detect near rhyme at the phenome level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHlHLUJt62Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Let's pretend that these phones are the same\n",
        "### (In addition all vowel phones that start with the same letter will be considered the same)\n",
        "NEAR_SETS = [['er', 'r'], \n",
        "             #['ih', 'eh'],\n",
        "             ['eh', 'ah'],\n",
        "             ['er', 'ax'],\n",
        "             ['ae', 'ey'],\n",
        "             ['t', 'f'],\n",
        "             ['b', 'k'],\n",
        "             ['p', 'z', 'th'],\n",
        "             ['s', 'st', 'sk'],\n",
        "             ['nt', 'ns'],\n",
        "             ['n', 'ng']\n",
        "             ]\n",
        "\n",
        "### These phonemes start with the same letter but should not be considered eqivalent\n",
        "FAR_SETS =[['aw', 'ay', 'ax'],\n",
        "           ['ax', 'ao']]\n",
        "\n",
        "### Determine if phonemes are a near match\n",
        "def near_match(phone1, phone2):\n",
        "  # Safety check\n",
        "  if (phone1 is None) or (phone2 is None) or (len(phone1) == 0 and len(phone2) > 0) or (len(phone2) == 0 and len(phone1) > 0):\n",
        "    return False\n",
        "  if phone1 == phone2:\n",
        "    # Phones are the same\n",
        "    return True\n",
        "  elif is_vowel_sound(phone1) and is_vowel_sound(phone2) and phone1[0] == phone2[0]:\n",
        "    # Vowel sounds start with the same letter\n",
        "    # Check that they are not in the same far set\n",
        "    for fs in FAR_SETS:\n",
        "      if phone1 in fs and phone2 in fs:\n",
        "        return False\n",
        "    return True\n",
        "  else:\n",
        "    # Check to see if the pair of phones are in the same near_set\n",
        "    for ns in NEAR_SETS:\n",
        "      if phone1 in ns and phone2 in ns:\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "### Check if every phone in list 1 is a near match to corresponding phone in list 2\n",
        "def near_matches(phone_list1, phone_list2):\n",
        "  if len(phone_list1) != len(phone_list2):\n",
        "    return False\n",
        "  else:\n",
        "    for i in range(len(phone_list1)):\n",
        "      if not near_match(phone_list1[i], phone_list2[i]):\n",
        "        return False\n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haav2wIAY8cj",
        "colab_type": "text"
      },
      "source": [
        "Detect near rhyme at the word level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0GdsPxb3Gtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### If you turn this on, it will print information about the phoneme analysis being conducted\n",
        "### every time near_rhyme() is called. Not recommended\n",
        "VERBOSE = False\n",
        "\n",
        "### Verbose print allows for debug printing to be turned off\n",
        "def vprint(*args):\n",
        "  if VERBOSE:\n",
        "    print(' '.join([str(a) for a in args]))\n",
        "\n",
        "### Determine if word1 and word2 are near rhymes\n",
        "### if last_consonant is False, we won't check for near matches of the last consonant\n",
        "def near_rhyme(word1, word2, last_consonant = True):\n",
        "  if perfect_rhyme(word1, word2):\n",
        "    return True\n",
        "  phonetic1 = Phonetic(word1)\n",
        "  phonetic2 = Phonetic(word2)\n",
        "  stress1 = phonetic1.all_stresses[-1] # The last stressed phone\n",
        "  stress2 = phonetic2.all_stresses[-1] # The last stressed phone\n",
        "  vprint(phonetic1.syllables_with_phones, phonetic1.all_stresses)\n",
        "  vprint(phonetic2.syllables_with_phones, phonetic2.all_stresses)\n",
        "  \n",
        "  # Word = a v x w c\n",
        "  # a = prefix (not important)\n",
        "  # v = last stressed vowel\n",
        "  # x = any number of phones between v and w\n",
        "  # w = last vowel\n",
        "  # c = consonant after last vowel\n",
        "  \n",
        "  # Last stressed vowel (v)\n",
        "  v1_index = stress1\n",
        "  v2_index = stress2\n",
        "  v1 = phonetic1.phones_list[v1_index]\n",
        "  v2 = phonetic2.phones_list[v2_index]\n",
        "  vprint('v:', v1, v1_index, v2, v2_index)\n",
        "\n",
        "  # Last vowel (w)\n",
        "  w1, w1_index = phonetic1.get_nth_vowel_phone(phonetic1.get_num_vowels()-1)\n",
        "  w2, w2_index = phonetic2.get_nth_vowel_phone(phonetic2.get_num_vowels()-1)\n",
        "  vprint('w:', w1, w1_index, w2, w2_index)\n",
        "\n",
        "  # Consonants after last vowel (c)\n",
        "  c1_index = w1_index + 1\n",
        "  c1 = ''.join(phonetic1.phones_list[c1_index:phonetic1.num_phones()])\n",
        "  c2_index = w2_index + 1\n",
        "  c2 = ''.join(phonetic2.phones_list[c2_index:phonetic2.num_phones()])\n",
        "  vprint('c:', c1, c1_index, c2, c2_index)\n",
        "\n",
        "  # phones between v and w (x)\n",
        "  x1 = phonetic1.phones_list[v1_index+1:w1_index]\n",
        "  x2 = phonetic2.phones_list[v2_index+1:w2_index]\n",
        "  vprint('x:', x1, x2)\n",
        "\n",
        "  # p = first phone in x\n",
        "  # q = last phone in x\n",
        "  p1 = None\n",
        "  q1 = None\n",
        "  p2 = None\n",
        "  q2 = None\n",
        "  if len(x1) > 0:\n",
        "    p1 = x1[0]\n",
        "    q1 = x1[-1]\n",
        "  if len(x2) > 0:\n",
        "    p2 = x2[0]\n",
        "    q2 = x2[-1]\n",
        "  vprint('p,q:', p1, q1, p2, q2)\n",
        "\n",
        "  if not near_match(w1, w2):\n",
        "    vprint('w fail')\n",
        "    return False\n",
        "  elif not near_match(v1, v2):\n",
        "    vprint('v fail')\n",
        "    return False\n",
        "  elif False and len(c1) != len(c2) and (len(c1) > 1 or len(c2) > 1): \n",
        "    vprint('c not same length - fail')\n",
        "    return False\n",
        "  elif last_consonant and not near_match(c1, c2):\n",
        "    vprint('cs dont match - fail')\n",
        "    return False\n",
        "  elif len(x1) == 0 and len(x2) == 0:\n",
        "    vprint(\"no x - match\")\n",
        "    return True\n",
        "  elif len(x1) == 1 and len(x2) == 1 and near_match(x1[0], x2[0]):\n",
        "    vprint('single x - match')\n",
        "    return True\n",
        "  elif len(x1) > 0 and len(x2) > 0 and num_vowel_phones(x1) != num_vowel_phones(x2):\n",
        "    vprint('num vowel phones in x - fail')\n",
        "    return False\n",
        "  elif near_match(p1, p2) and near_match(q1, q2):\n",
        "    vprint('ps or qs - match')\n",
        "    return True\n",
        "  return False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESJrxw3F7Ygo",
        "colab_type": "text"
      },
      "source": [
        "## Load Near Rhyme Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRw1MR7xvCIg",
        "colab_type": "text"
      },
      "source": [
        "Download the near-rhyme dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3e2-iuTu8wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(NEAR_RHYME_PATH): \n",
        "  !wget https://www.dropbox.com/s/8a800ivlp0uknic/near_rhymes20000.zip?dl=1 -O near_rhymes20000.zip\n",
        "  !unzip near_rhymes20000.zip\n",
        "if not os.path.exists(PHONE_CACHE_PATH):\n",
        "  !wget https://www.dropbox.com/s/i57hvmnlint7wj3/phone_cache.zip?dl=1 -O phone_cache.zip\n",
        "  !unzip phone_cache.zip\n",
        "if not os.path.exists(NEAR_RHYME_PATH):\n",
        "  shutil.copyfile(NEAR_RHYME_DICT_FILENAME, NEAR_RHYME_PATH)\n",
        "if not os.path.exists(PHONE_CACHE_PATH):\n",
        "  shutil.copyfile(PHONE_CACHE_FILENAME, PHONE_CACHE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnIVVEKmvGKv",
        "colab_type": "text"
      },
      "source": [
        "Load the near-rhyme dictionary into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAdE5KR-vJcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists(NEAR_RHYME_PATH):\n",
        "  NEAR_RHYME_DICT = load_near_rhyme_dictionary(NEAR_RHYME_PATH)\n",
        "\n",
        "if os.path.exists(PHONE_CACHE_PATH):\n",
        "  PHONE_CACHE = load_phone_cache(PHONE_CACHE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGgxJzjYOw1",
        "colab_type": "text"
      },
      "source": [
        "## Make a near-rhyme dictionary\n",
        "\n",
        "Searching for near-rhymes is expensive. Pre-compute near-rhymes and store them to disk.\n",
        "\n",
        "This only needs to be run once and the near-rhyme dictionary is made available for download. The only reason to run this function would be if you made changes to ``near_rhyme()``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwuHnrvJDVOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Make a dictionary remembering whether words are near rhymes to each other.\n",
        "def make_near_rhyme_dictionary(top_n, filename, rhyme_dict=None):\n",
        "  global VERBOSE\n",
        "  VERBOSE = False   # Turn off debugging prints\n",
        "  near_rhymes = []\n",
        "  # Get top n most frequent words\n",
        "  top = top_n_list('en', top_n, wordlist='best')\n",
        "  for i, w1 in enumerate(top):\n",
        "    for j, w2 in enumerate(top):\n",
        "      if is_word(w1) and is_word(w2) and w1 != w2:\n",
        "        if rhyme_dict is None or w1 not in rhyme_dict or w2 not in rhyme_dict[w1]: \n",
        "          if near_rhyme(w1, w2):\n",
        "            print(\"MATCH\", i, j, w1, w2,)\n",
        "            near_rhymes.append((w1, w2))\n",
        "  if rhyme_dict is not None:\n",
        "    for key in list(rhyme_dict.keys()):\n",
        "      for val in rhyme_dict[key]:\n",
        "        near_rhymes.append((key, val))\n",
        "        near_rhymes.append((val, key))\n",
        "  with open(filename, 'w') as f:\n",
        "    for w1, w2 in near_rhymes:\n",
        "      f.write(w1 + '\\t' + w2 + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gPtx7krZCqx",
        "colab_type": "text"
      },
      "source": [
        "Don't run this unless you want to rebuild the near-ryme dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SgY9-p5NwRiF",
        "colab": {}
      },
      "source": [
        "build_near_rhyme_dictionary = False #@param {type:\"boolean\"}\n",
        "if build_near_rhyme_dictionary:\n",
        "  make_near_rhyme_dictionary(20000, NEAR_RHYME_PATH)\n",
        "  save_phone_cache(PHONE_CACHE, PHONE_CACHE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJT9WydO8bZB",
        "colab_type": "text"
      },
      "source": [
        "## Load neural language models\n",
        "\n",
        "GPT-2 is probably the best generator we use, but it only goes forward. We only use GPT-2 when we are generating a line that has an unconstrained rhyme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlb6rJBD8Mgr",
        "colab_type": "code",
        "outputId": "490c416d-572d-4922-e1ce-e97e727fe0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "8057b6da0fc046b781704d10924f2802",
            "b819f45670334c6f90d8cda75aa4b7ba",
            "6ab02a36c66e4960abfb127a30f8fc72",
            "bfee079c61824313ad3e1ec321825454",
            "9d78cdb0302e4d32bc95a92267269f2a",
            "33d5644645e24eabb8b92329da3236de",
            "779c006efb5e463ea5651c5df2e174ef",
            "90c730bed147496d8a3629bd87cff9ed",
            "88fdcace049246e3a17360e386956271",
            "09dbc8ef2cf94d2cb57458d9274feab3",
            "a9119ebed68447c69f1ca7bdd464559b",
            "c1fc0713496946a7aae03d9ca9ae79bd",
            "50777f756c1640778945694c1906a04c",
            "21aa838693284bc0a189f4fc4f390536",
            "dcd6382126e74f58bd9ad483e7d3a984",
            "54a385de6cc64250a445c4821d43710e",
            "5ed327819ffb45f69bf7c1eb1ad14c58",
            "a87a7cb86dc244ce8e4416b87314fb9d",
            "c2d9ab815035439ca7e148fab8c28067",
            "13e43bc5ee35460f9be906f1e07eb72e",
            "abc1286341ef46e8a87f0bfacd7bceb9",
            "fd328d7fabe84c6ab1d2a60b4f736ac6",
            "2aafadfa176a43db8c44c706fbe183ff",
            "8bafb6152a3f4b85b3d0f800a55677dd",
            "fe1c493dc7824226826434def09b6ae3",
            "d8ad1c0483054b4caedf733a872f0384",
            "25ac9648dee94734a02487206b8c7a11",
            "b6ebade1c0124d38a15dd2a4e09de4d7",
            "b50e5ae3b43a47fe947f37878857b50c",
            "45de42eea75b463f8c3bda6e6754ccfb",
            "cfb350ac58f849d0a7683df7b55fc3d3",
            "1cff023a67644dc5b0e149a6a34c0e0a"
          ]
        }
      },
      "source": [
        "GPT_TOKENIZER = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "GPT = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "GPT.eval()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8057b6da0fc046b781704d10924f2802",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88fdcace049246e3a17360e386956271",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ed327819ffb45f69bf7c1eb1ad14c58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe1c493dc7824226826434def09b6ae3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWuLSNXVa7pp",
        "colab_type": "text"
      },
      "source": [
        "XLNET can generate forward and backward and fill in the middle of a sentence (sort of, we have to force it to operate this way)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UX0_jlq8k9H",
        "colab_type": "code",
        "outputId": "2cccd770-1723-4665-dfed-29bf83e074a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "68b50b92e41241e187ee1e4cb9da425f",
            "376625c70db9472f9bbbd9e7b55b49b8",
            "c275de4e48f84ca1be6be1277e01cf2f",
            "cd15e53d3d034512aaaa30614ba1b167",
            "8c8fc494284b4b6697bedc2ba2ac7d73",
            "00683170ccb54e6cae8974d59e2bc2dd",
            "c2db9a8561c44cdc8bcf044d9ae1329a",
            "bc88fbc26d204fe3a5b796f8bdd35db7",
            "e2f35ed1851e42d398894507bc4f1ce5",
            "f3df3c03c89c4c37945f8e6fecde4514",
            "49991112adb24f4a952d5793090e6b74",
            "5c330a51c41e44bf814c5739164fe8eb",
            "555dcd3fa91d4090806b3b00a5241db0",
            "343c371cc74842a1b97cc4a212885e4d",
            "14439330b46944fd840d4b274d921bf8",
            "1a005b531dba40dab26fbe49b9d6b49c",
            "4043bd5b0d40441a9403736bb32fdc2d",
            "eb0bce2e16984225bd94e94a1b347506",
            "1616bcf8a7854ac39c8d5c87d977ef4b",
            "09ed7f5dd5634bf391c5c38c64fecb86",
            "f61caef45ec14d4a89684dedb99ff1c2",
            "e6148cdb1cf84143af77a20dd9c5038d",
            "909e12639ee94fe6a66ecc4169b5bdb1",
            "26f714b50c104adc9dd0bc1632ea0580"
          ]
        }
      },
      "source": [
        "XLNET_TOKENIZER = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
        "XLNET = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
        "XLNET.eval()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68b50b92e41241e187ee1e4cb9da425f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f35ed1851e42d398894507bc4f1ce5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=761.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4043bd5b0d40441a9403736bb32fdc2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1441285815.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetLMHeadModel(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 1024)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (12): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (13): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (14): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (15): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (16): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (17): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (18): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (19): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (20): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (21): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (22): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (23): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_loss): Linear(in_features=1024, out_features=32000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPHI36TcbRu1",
        "colab_type": "text"
      },
      "source": [
        "I was running into memory issues, so we only keep one neural language model in GPU memory at a time. This sets up ```@use_gpt``` and ```@use_xlnet``` function decorators. Put this before any function that will use either GPT-2 or XLNET. For example:\n",
        "```\n",
        "@use_gpt\n",
        "def my_cool_function(inputs):\n",
        "  outputs = GPT(inputs)\n",
        "  return outputs\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puqC81bR-qTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Are GPUs available?\n",
        "CUDA_AVAILABLE = torch.cuda.is_available()\n",
        "\n",
        "# Which model is in the GPU (string)\n",
        "MODEL_IN_GPU = None        \n",
        "# Which models are we using and what are their names?\n",
        "MODEL_HASH = {'gpt': GPT, 'xlnet': XLNET}\n",
        "\n",
        "def _prep_model(model_name):\n",
        "  global MODEL_IN_GPU\n",
        "  global MODELS_NOT_IN_GPU\n",
        "  if MODEL_IN_GPU != model_name:\n",
        "    # Unload the model in the gpu (if any)\n",
        "    if MODEL_IN_GPU is not None:\n",
        "      MODEL_HASH[MODEL_IN_GPU].to('cpu')\n",
        "      MODEL_IN_GPU = None\n",
        "    # Load the new model to gpu\n",
        "    if CUDA_AVAILABLE:\n",
        "      print(\"LOADING\", model_name)\n",
        "      MODEL_HASH[model_name].to('cuda')\n",
        "      MODEL_IN_GPU = model_name\n",
        "\n",
        "# For backward compatibility:\n",
        "def prep_gpt():\n",
        "  _prep_model('gpt')\n",
        "\n",
        "def prep_xlnet():\n",
        "  _prep_model('xlnet')\n",
        "\n",
        "# Decorators!\n",
        "def use_gpt(func):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    _prep_model('gpt')\n",
        "    return func(*args, **kwargs)\n",
        "  return wrapper\n",
        "\n",
        "def use_xlnet(func):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    _prep_model('xlnet')\n",
        "    return func(*args, **kwargs)\n",
        "  return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpj25sSTOB9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### This does top-k and top-p sampling from a list of logits. Borrowed from original GPT-2 code.\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
        "        Args:\n",
        "            logits: logits distribution shape (vocabulary size)\n",
        "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
        "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
        "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
        "    \"\"\"\n",
        "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
        "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
        "    if top_k > 0:\n",
        "        # Remove all tokens with a probability less than the last token of the top-k\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfh6KBPaJBRt",
        "colab_type": "text"
      },
      "source": [
        "##Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiNXarNSJAZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### These are punctuation\n",
        "PUNCTUATION = ['.', ',', '-', '?', '!', ':', '_', '$', '%', '&', '#', '@', '*', '(', ')', '+', '=', '[', ']', '{', '}']\n",
        "### These are numbers\n",
        "NUMBERS = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
        "### Periods are important\n",
        "PERIOD = '.'\n",
        "BLANK = ' '\n",
        "\n",
        "### Is this string punctuation?\n",
        "def is_punctuation(s):\n",
        "  return len(set(s).intersection(set(PUNCTUATION))) > 0\n",
        "\n",
        "### Remove punctuation from string\n",
        "def remove_punctuation(s):\n",
        "  return ''.join(i for i in s if not i in PUNCTUATION) \n",
        "\n",
        "### How many syllables in this string?\n",
        "def get_syllables_for_line(line):\n",
        "  line = ''.join(list(filter(lambda c: c in STR_LETTERS or c == BLANK, line)))\n",
        "  count = 0\n",
        "  words = line.split()\n",
        "  for word in words:\n",
        "    word = word.strip()\n",
        "    if len(word) > 0 and is_word(word):\n",
        "      phonetic = Phonetic(word)\n",
        "      count = count + phonetic.num_syllables()\n",
        "  return count\n",
        "\n",
        "### Remove the prefix from the string (s)\n",
        "def remove_prefix(s, prefix):\n",
        "    rest = s[len(prefix):] if s.startswith(prefix) else s\n",
        "    return rest\n",
        "\n",
        "### The system considers whether to terminate a line after the line is generated.\n",
        "### So punctuation of a line could end up in the next line down.\n",
        "def fix_final_lines_punctuation(lines):\n",
        "  new_lines = []\n",
        "  for i, line in enumerate(lines):\n",
        "    if i > 0 and line[0] in PUNCTUATION:\n",
        "      new_lines[-1] = new_lines[-1] + line[0]\n",
        "      new_lines.append(line[1:].strip())\n",
        "    else: \n",
        "      new_lines.append(line.strip())\n",
        "  return new_lines\n",
        "\n",
        "def fix_final_lines_capitalization(lines):\n",
        "  new_lines = []\n",
        "  for line in lines:\n",
        "    new_line = line[0].upper() + line[1:].lower()\n",
        "    new_lines.append(new_line)\n",
        "  return new_lines\n",
        "\n",
        "### Figure out how to put two lines (strings) together.\n",
        "### If force_break is True, then put a sentence break (period) between the two.\n",
        "### Otherwise, try to figure out if there should be a period between.\n",
        "def merge_lines(l1, l2, force_break = False):\n",
        "  if len(l1) == 0:\n",
        "    return l2\n",
        "  elif len(l2) == 0 and force_break:\n",
        "    return l1 + PERIOD\n",
        "  elif len(l2) == 0:\n",
        "    return l1\n",
        "  elif not is_punctuation(l1[-1]) and force_break:\n",
        "    return l1 + PERIOD + BLANK + l2\n",
        "  else:\n",
        "    return l1 + BLANK + l2\n",
        "\n",
        "### Figure out which xlnet tokens are numbers\n",
        "def xlnet_number_tokens():\n",
        "  nums = []\n",
        "  for i in range(len(XLNET_TOKENIZER.get_vocab())):\n",
        "    s = XLNET_TOKENIZER.decode(i)\n",
        "    if len(s) > 0 and len(set(s).intersection(set(NUMBERS))) > 0: #s[0] in NUMBERS:\n",
        "      nums.append((i, s))\n",
        "  return nums\n",
        "\n",
        "### Figure out which gpt tokens are numbers\n",
        "def gpt_number_tokens():\n",
        "  nums = []\n",
        "  for i in range(len(GPT_TOKENIZER.get_vocab())):\n",
        "    s = GPT_TOKENIZER.decode(i)\n",
        "    if len(s) > 0 and len(set(s).intersection(set(NUMBERS))) > 0: #s[0] in NUMBERS:\n",
        "      nums.append((i, s))\n",
        "  return nums\n",
        "\n",
        "### Find all the numbers in xlnet and gpt vocabularies\n",
        "XLNET_NUMBER_TOKENS = list(map(lambda x: x[0], xlnet_number_tokens()))\n",
        "GPT_NUMBER_TOKENS = list(map(lambda x: x[0], gpt_number_tokens()))\n",
        "\n",
        "### Print lyrics \n",
        "def pretty_print(lines):\n",
        "  print('---------')\n",
        "  for line in lines:\n",
        "    print(line)\n",
        "  print('---------')\n",
        "\n",
        "EXCLAIMS = ['oh!', 'ah!', 'yeah!']\n",
        "\n",
        "## If we don't have enough syllables, add some ohs ahs and yeahs\n",
        "def add_filler(line, count, start):\n",
        "  prefix = line[0:start]\n",
        "  suffix = line[start:]\n",
        "  filler = []\n",
        "  for i in range(count):\n",
        "    filler.append(random.choice(EXCLAIMS))\n",
        "  return prefix + BLANK + BLANK.join(filler) + BLANK + suffix\n",
        "\n",
        "## We get weird punctuation. Remove it\n",
        "def remove_extra_punctuation(line):\n",
        "  idx = len(line)\n",
        "  for i in range(1, len(line)):\n",
        "    pos = len(line) - i\n",
        "    if line[pos] in PUNCTUATION:\n",
        "      idx = pos\n",
        "    else:\n",
        "      break\n",
        "  return line[0:idx]\n",
        "\n",
        "### Merge two dictionaries.\n",
        "### The dictionaries should contain lists as values.\n",
        "def merge_dicts(dict1, dict2):\n",
        "  if dict1 is None or dict2 is None:\n",
        "    return {}\n",
        "  new_dict = copy.deepcopy(dict1)\n",
        "  for key in list(dict2.keys()):\n",
        "    val_list = dict2[key]\n",
        "    if key not in new_dict:\n",
        "      new_dict[key] = []\n",
        "    new_dict[key] += val_list\n",
        "  return new_dict\n",
        "\n",
        "### Count how many times each word occurs in a line.\n",
        "def word_counts(line):\n",
        "  counts = {}\n",
        "  new_line = ''.join(list(filter(lambda c: c not in PUNCTUATION, line)))\n",
        "  for word in new_line.split():\n",
        "    if word not in counts:\n",
        "      counts[word] = 0\n",
        "    counts[word] += 1\n",
        "  return counts\n",
        "\n",
        "### Get rid of any lines that uses a word more than once\n",
        "def filter_lines(lines):\n",
        "  return list(filter(lambda line: max(word_counts(line).values()) <= 1, lines))\n",
        "\n",
        "### Make sure our lines don't get too long\n",
        "def crop_line(line):\n",
        "  enc = GPT_TOKENIZER.encode(line)\n",
        "  if len(enc) > MAX_CONTEXT_LENGTH:\n",
        "    enc = enc[len(enc)-MAX_CONTEXT_LENGTH:]\n",
        "  dec = GPT_TOKENIZER.decode(enc)\n",
        "  return dec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BoaMdQ1GSYP",
        "colab_type": "text"
      },
      "source": [
        "##Post-processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPo-jcPTs2wr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Provide a specification hash where keys are line numbers and the values are ```(pre, post)``` such that ```pre``` is a string (or None) that should be prepended to the line and ```post``` is a string (or none) that should be appended to the line.\n",
        "\n",
        "```Pre``` and ```post``` can include special commands in brackets to do complex post-processing. Currently the commans supported are:\n",
        "\n",
        "- ```{repeat n}``` to repeat the last n syllables in the line (or \"all\").\n",
        "- ```{frepeat n}``` to repeat the first n syllables in the line (or \"all\")\n",
        "- ```{copy n}``` to copy the nth line and insert it directly after the line indicated by the key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73NX2UuQSKrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def repeat_fn(line, all_lines, line_number, spec, args):\n",
        "  target_syllables = args[0]\n",
        "  ref_line = all_lines[line_number]\n",
        "  ref_line = ''.join(c for c in ref_line if not c in PUNCTUATION) \n",
        "  if target_syllables == 'all':\n",
        "    return ref_line, all_lines, line_number, spec\n",
        "  else:\n",
        "    ref_line_words = ref_line.split()\n",
        "    syllable_count = 0\n",
        "    picked_words = []\n",
        "    for word in reversed(ref_line_words):\n",
        "      num_syllables = get_syllables_for_line(word)\n",
        "      syllable_count = syllable_count + num_syllables\n",
        "      picked_words.append(word)\n",
        "      if syllable_count >= target_syllables:\n",
        "        break\n",
        "    return BLANK.join(reversed(picked_words)), all_lines, line_number, spec\n",
        "\n",
        "def frepeat_fn(line, all_lines, line_number, spec, args):\n",
        "  target_syllables = args[0]\n",
        "  ref_line = all_lines[line_number]\n",
        "  ref_line = ''.join(c for c in ref_line if not c in PUNCTUATION) \n",
        "  if target_syllables == 'all':\n",
        "    return ref_line, all_lines, line_number, spec\n",
        "  else:\n",
        "    ref_line_words = ref_line.split()\n",
        "    syllable_count = 0\n",
        "    picked_words = []\n",
        "    for word in reversed(ref_line_words):\n",
        "      num_syllables = get_syllables_for_line(word)\n",
        "      syllable_count = syllable_count + num_syllables\n",
        "      picked_words.append(word)\n",
        "      if syllable_count >= target_syllables:\n",
        "        break\n",
        "    return BLANK.join(reversed(picked_words)), all_lines, line_number, spec\n",
        "\n",
        "def copy_fn(line, all_lines, line_number, spec, args):\n",
        "  new_spec = {}\n",
        "  line_to_copy = args[0]\n",
        "  copied_line = all_lines[line_to_copy]\n",
        "  new_all_lines = all_lines[0:line_number+1] + [copied_line] + all_lines[line_number+1:]\n",
        "  for key in list(spec.keys()):\n",
        "    val = spec[key]\n",
        "    if key > line_number:\n",
        "      new_spec[key+1] = val\n",
        "    else:\n",
        "      new_spec[key] = val\n",
        "  return '', new_all_lines, line_number, new_spec\n",
        "\n",
        "PARSE_FUNCTIONS = {'repeat': repeat_fn, \"copy\": copy_fn, 'frepeat': frepeat_fn}\n",
        "\n",
        "def parse(line, all_lines, line_number, spec):\n",
        "  done = False\n",
        "  while not done:\n",
        "    match = re.search(r'\\{([\\w]+)[ ]*([\\w, ]*)\\}', line)\n",
        "    if match is None:\n",
        "      done = True\n",
        "    else:\n",
        "      func = match.groups()[0]\n",
        "      args = eval(match.groups()[1])\n",
        "      if not isinstance(args, tuple):\n",
        "        args = tuple([args])\n",
        "      pre = line[0:match.start()]\n",
        "      mid, all_lines, line_number, spec = PARSE_FUNCTIONS[func](line, all_lines, line_number, spec, args)\n",
        "      post = line[match.end():]\n",
        "      line = pre + mid + post\n",
        "  return line, all_lines, line_number, spec\n",
        "\n",
        "### Add post-processing information to each line\n",
        "def post_process_lines(lines, spec):\n",
        "  new_lines = []\n",
        "  i = 0\n",
        "  while i < len(lines):\n",
        "    line = lines[i]\n",
        "    if i in spec:\n",
        "      pre, post = spec[i]\n",
        "      if pre is not None:\n",
        "        pre, lines, i, spec = parse(pre, lines, i, spec) if pre is not None else ''\n",
        "        line = lines[i]\n",
        "      else:\n",
        "        pre = ''\n",
        "      if post is not None:\n",
        "        post, lines, i, spec = parse(post, lines, i, spec) if post is not None else ''\n",
        "        line = lines[i]\n",
        "      else:\n",
        "        post = ''\n",
        "      new_lines.append(pre + line + post)\n",
        "    else:\n",
        "      new_lines.append(line)\n",
        "    i = i +1\n",
        "  return new_lines\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2t9Cd4d8zif",
        "colab_type": "text"
      },
      "source": [
        "## Picking Rhymes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SpMvUWFrqgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ### Pick the word from the words list that is most similar to the context according to BERT\n",
        " @use_gpt\n",
        " def pick_similar(context, words, history = []): \n",
        "  token_hash = {}\n",
        "  for word in words:\n",
        "    token_hash[tuple(GPT_TOKENIZER.encode(word))] = None\n",
        "  #prep_gpt()\n",
        "  context_tokens = GPT_TOKENIZER.encode(context) \n",
        "  prompt = torch.tensor([context_tokens]) # context put into the right shape\n",
        "  prompt = prompt.to('cuda') if CUDA_AVAILABLE else prompt\n",
        "  past = None \n",
        "  beams = []\n",
        "  for i in range(10):\n",
        "    current_beam = []\n",
        "    for j in range(20):\n",
        "      # Generate\n",
        "      output, new_past = GPT(prompt, past=past)\n",
        "      # Top k filter: there are k real numbers and the rest are -inf\n",
        "      logits = output[0][0][:]\n",
        "      #top_k_logits = top_k_top_p_filtering(output[0][0], top_k=SAMPLE_K)\n",
        "      tokens = torch.multinomial(F.softmax(logits), 1)\n",
        "      token = tokens[0]\n",
        "      if token == 13:\n",
        "        break\n",
        "      else:\n",
        "        current_beam.append((token, logits))\n",
        "        prompt = torch.tensor([token]).unsqueeze(0)\n",
        "        prompt = prompt.to('cuda')\n",
        "        past = new_past\n",
        "    beams.append(current_beam)\n",
        "  # ASSERT: we have 10 beams of 20 tokens or less\n",
        "  for key in list(token_hash.keys()):\n",
        "    sum = 0\n",
        "    for beam in beams:\n",
        "      for i in range(len(beam)):\n",
        "        for j, tok in enumerate(key):\n",
        "          if i+j < len(beam):\n",
        "            logits = beam[i+j][1]\n",
        "            sum = sum + logits[tok]\n",
        "        if len(key) > 1:\n",
        "          sum = sum / len(key)\n",
        "      #if len(beam) > 1:\n",
        "      #  sum = sum / len(beam)\n",
        "    if token_hash[key] is None:\n",
        "      token_hash[key] = sum\n",
        "    else:\n",
        "      token_hash[key] = token_hash[key] + sum\n",
        "  # ASSERT: Token_hash populated with good values\n",
        "  vals = torch.stack(list(token_hash.values()))\n",
        "  soft = F.softmax(vals)\n",
        "  mask = soft > 0.0\n",
        "  num_nonzero = torch.sum(mask.int())\n",
        "  topk = torch.multinomial(soft, min(10, len(words), num_nonzero.item()), replacement=False).tolist()\n",
        "  print(\"Picking from:\", list(map(lambda x: words[x], topk)), \"given history\", history)\n",
        "  final_pick = None\n",
        "  for idx in topk:\n",
        "    if words[idx] not in history:\n",
        "      final_pick = words[idx]\n",
        "      break\n",
        "  if final_pick is None:\n",
        "    # Uh oh we didn't find anything, probably because all the hits were in history\n",
        "    sorted_words = sorted(words, key=lambda w: token_hash[tuple(GPT_TOKENIZER.encode(w))], reverse=True)\n",
        "    print(\"Second attempt\", sorted_words, \"history\", history)\n",
        "    final_pick = None\n",
        "    for w in sorted_words:\n",
        "      if w not in history:\n",
        "        final_pick = w\n",
        "        break\n",
        "    if final_pick is None:\n",
        "      weights = list(map(lambda w: -token_hash[tuple(GPT_TOKENIZER.encode(w))], sorted_words))\n",
        "      print(\"Third attempt\", list(zip(sorted_words, weights)), \"history\", history)\n",
        "      final_pick = random.choices(sorted_words, weights)[0]\n",
        "  print(\"Picking\", final_pick)\n",
        "  return final_pick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rPcqa0OHA8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NO_RHYME_WORDS = ['francoise', \"l'enfant\", 'un', 'vanhove', \"suhud\",\n",
        "                  're', 'le', 'tao', 'mao', 'lao', 'petr', 'chas', 'rao', 'raby', 'rabey', \n",
        "                  'ia', 'co', 'uk', 'a', 'i']\n",
        "\n",
        "### Remove some words from rhyme dictionary\n",
        "def filter_rhyme(word):\n",
        "  return (PERIOD not in word) and \\\n",
        "          ('-' not in word) and \\\n",
        "          (len(word) > 1 or word == 'a' or word == 'I' or word == 'i') and \\\n",
        "          (word.lower() not in NO_RHYME_WORDS)\n",
        "\n",
        "### Uniformly pick amongst top k most frequent perfect rhymes\n",
        "def pick_perfect_rhyme(word, context = None, history=[]):\n",
        "  # Remove unwanted letters\n",
        "  word = ''.join(list(filter(lambda c: c in STR_LETTERS, word)))\n",
        "  # Get rhymes\n",
        "  rhymes = pronouncing.rhymes(word)\n",
        "  # Remove unwanted words\n",
        "  rhymes = list(filter(lambda w: filter_rhyme(w), rhymes))\n",
        "  # If there aren't any rhymes, return the current word\n",
        "  if len(rhymes) == 0:\n",
        "    return word\n",
        "  else:\n",
        "    # Make sure k is smaller than total number of rhymes available\n",
        "    k = min(RHYME_K, len(rhymes))\n",
        "    # Get word frequency of rhymes\n",
        "    probs = list(map(lambda r: word_frequency(r, 'en'), rhymes))\n",
        "    probs_tensor = torch.tensor(probs)\n",
        "    # Get top k\n",
        "    vals, idxs = torch.topk(probs_tensor, k)\n",
        "    if context is not None and len(context) > 0:\n",
        "      candidates = [rhymes[x] for x in idxs.tolist()]\n",
        "      pick = pick_similar(context, candidates, history)\n",
        "      return pick\n",
        "    else:\n",
        "      # Pick uniformly\n",
        "      r = random.randint(0, k-1)\n",
        "      return rhymes[idxs[r].item()]\n",
        "\n",
        "### Pick best near rhyme from the near rhyme dictionary\n",
        "def pick_near_rhyme(word, context = None, history = []):\n",
        "  global NEAR_RHYME_DICT\n",
        "  if NEAR_RHYME_DICT is None:\n",
        "    NEAR_RHYME_DICT = load_near_rhyme_dictionary(NEAR_RHYME_PATH)\n",
        "  # Remove unwanted letters\n",
        "  word = ''.join(list(filter(lambda c: c in STR_LETTERS, word)))\n",
        "  # Get rhymes\n",
        "  near_rhymes = []\n",
        "  #rhymes = []\n",
        "  if word in NEAR_RHYME_DICT:\n",
        "    near_rhymes = NEAR_RHYME_DICT[word]\n",
        "  if len(near_rhymes) > 0:\n",
        "    rhymes = near_rhymes\n",
        "  #else:\n",
        "  #  rhymes = pronouncing.rhymes(word)\n",
        "  rhymes = list(set(near_rhymes + pronouncing.rhymes(word)))\n",
        "  # Remove unwanted words\n",
        "  rhymes = list(filter(lambda w: filter_rhyme(w), rhymes))\n",
        "  # If there aren't any rhymes, return the current word\n",
        "  if len(rhymes) == 0:\n",
        "    return word\n",
        "  else:\n",
        "    # Make sure k is smaller than total number of rhymes available\n",
        "    k = min(RHYME_K, len(rhymes))\n",
        "    # Get word frequency of rhymes\n",
        "    probs = list(map(lambda r: word_frequency(r, 'en'), rhymes))\n",
        "    probs_tensor = torch.tensor(probs)\n",
        "    # Get top k\n",
        "    vals, idxs = torch.topk(probs_tensor, k)\n",
        "    if context is not None and len(context) > 0:\n",
        "      candidates = [rhymes[x] for x in idxs.tolist()]\n",
        "      pick = pick_similar(context, candidates, history)\n",
        "      return pick\n",
        "    else:\n",
        "      # Pick uniformly\n",
        "      r = random.randint(0, k-1)\n",
        "      return rhymes[idxs[r].item()]\n",
        "\n",
        "### Pick rhyme, redirects to pick_perfect_rhyme or pick_near_rhyme\n",
        "def pick_rhyme(word, perfect=True, context=None, history=[]):\n",
        "  if perfect:\n",
        "    return pick_perfect_rhyme(word, context=context, history=history)\n",
        "  else:\n",
        "    return pick_near_rhyme(word, context=context, history=history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLdfSu2GfTA",
        "colab_type": "text"
      },
      "source": [
        "## Lyrics Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xB0K0RMGsjY",
        "colab_type": "text"
      },
      "source": [
        "Compute a score for a segment of lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiWmyvPbGp45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOSS = torch.nn.CrossEntropyLoss(reduction='sum')  \n",
        "\n",
        "def interactive_pick_line(lines):\n",
        "  result = None\n",
        "  print(\"GENERATED CANDIDATES:\")\n",
        "  for i, line in enumerate(lines):\n",
        "    print('[' + str(i) + '] ' + line)\n",
        "  inp = input(\"CHOOSE BY NUMBER (0-\" + str(len(lines)-1) + \") OR WRITE YOUR OWN: \")\n",
        "  try:\n",
        "    idx = int(inp)\n",
        "    result = lines[idx]\n",
        "  except ValueError:\n",
        "    result = inp\n",
        "  return result, INF\n",
        "\n",
        "\n",
        "### Score a sentence, lower is better (cross entropy)\n",
        "@use_gpt\n",
        "def score_sentence(sentence):\n",
        "  #encode sentence\n",
        "  prompt = GPT_TOKENIZER.encode(sentence)\n",
        "  # Set up x and y as shifted input\n",
        "  x = torch.tensor([prompt[:-1]])\n",
        "  y = torch.tensor(prompt[1:])\n",
        "  if CUDA_AVAILABLE:\n",
        "    x = x.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "  #prep_gpt()  \n",
        "  # Measure the logits for loss\n",
        "  output, new_past = GPT(x, past=None)\n",
        "  score = LOSS(output[0], y)\n",
        "  return score\n",
        "\n",
        "\n",
        "### Pick the best line. Run them all through the scoring function and pick the smallest\n",
        "def pick_best_line(lines, context, history = [], interactive=False):\n",
        "  if interactive:\n",
        "    return interactive_pick_line(lines)\n",
        "  else:\n",
        "    # Remove duplicates\n",
        "    modified_history = list(map(lambda s: remove_punctuation(s).encode('ascii', 'ignore').lower(), history))\n",
        "    lines = list(filter(lambda s: remove_punctuation(s).encode('ascii', 'ignore').lower() not in modified_history, lines))\n",
        "    # Score sentences\n",
        "    scores = list(map(lambda l:score_sentence(merge_lines(context, l)), lines))\n",
        "    scores_tensor = torch.tensor(scores, dtype=torch.float)\n",
        "    #for i, line in enumerate(lines):\n",
        "    #  print(\"SCORE\", scores[i].item(), line)\n",
        "    # Get smallest\n",
        "    if len(lines) == 1:\n",
        "      return lines[0], scores[0].item()\n",
        "    elif GREEDY_PICK_LINE:\n",
        "      vals, idxs = torch.topk(scores_tensor, 1, largest=False)\n",
        "      idx = idxs[0].item()\n",
        "      return lines[idx], vals[0].item()\n",
        "    else:\n",
        "      try:\n",
        "        shifted = (scores_tensor-min(scores_tensor))\n",
        "        flipped = (max(shifted) - shifted).div(max(shifted))\n",
        "        exped = flipped.div(PICK_LINE_TEMPERATURE).exp()\n",
        "        idxs = torch.multinomial(exped, 1)\n",
        "        idx = idxs[0].item()\n",
        "      except:\n",
        "        # Probably a div by zero\n",
        "        # Usually caused when all the sentences are the same and thus have the same scores\n",
        "        # Which means shifted is a tensor of 0s\n",
        "        idx = 0\n",
        "      print(\"PICK\", lines[idx])\n",
        "      return lines[idx], scores[idx].item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FBRWK4vG2t7",
        "colab_type": "text"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF-qFh_083UY",
        "colab_type": "text"
      },
      "source": [
        "Fill in masks between context and a rhyme (ending)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RibFtz0Dfzg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASK_IDX = 6                          # MASK is token id 6\n",
        "# Things I don't want generated\n",
        "XLNET_NO_TOKENS = [6, 7, 8, 0, 1, 2, 3, 4, 5,\n",
        "                   10, 11, 12, 13, 14, 15, 16, 2055, 6490, 26,\n",
        "                   97, 167, 225, 4145, 3158, 17115, 22891, 17666, 4538] + XLNET_NUMBER_TOKENS\n",
        "NINF = -float('Inf')                  # Negative infinity\n",
        "INF = float('Inf')                    # Positive infinity\n",
        "\n",
        "### Given a prompt, with one or more '<mask>' in it, fill the masks in with XLNET \n",
        "### Can go forward or backward. Backward seems to work better?\n",
        "@use_xlnet\n",
        "def fill_line(prompt, backward=False):\n",
        "  generated_tokens = []\n",
        "  # Convert prompt into tokens\n",
        "  input_ids = torch.tensor(XLNET_TOKENIZER.encode(prompt, add_special_tokens=False)).unsqueeze(0)  \n",
        "  # mask out the places we want to predict\n",
        "  perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
        "  masked = input_ids == MASK_IDX\n",
        "  perm_mask = perm_mask + masked\n",
        "  # The places we want to predict are...\n",
        "  predicts = torch.nonzero(masked[0]).tolist()\n",
        "  if backward:\n",
        "    predicts = list(reversed(predicts))\n",
        "  # Set up a diagonal where we want to predict, dim=0 is batch, dim=1 is each prediction\n",
        "  target_mapping = torch.zeros((1, len(predicts), input_ids.shape[1]), dtype=torch.float)  \n",
        "  for n, p in enumerate(predicts):\n",
        "    target_mapping[0][n][p] = 1.0\n",
        "  #prep_xlnet()\n",
        "  if CUDA_AVAILABLE:\n",
        "    input_ids = input_ids.to('cuda')\n",
        "    perm_mask = perm_mask.to('cuda')\n",
        "    target_mapping = target_mapping.to('cuda')\n",
        "\n",
        "  # Fill one mask at a time until there are no places to fill (predicts is empty)\n",
        "  while len(predicts) > 0:\n",
        "    # Predict everything, but ignore all but the first prediction\n",
        "    outputs = XLNET(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
        "    next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
        "    # Filter to top-k\n",
        "    logits = top_k_top_p_filtering(next_token_logits[0][0], top_k=SAMPLE_K)\n",
        "    # Sample from top-k\n",
        "    samples = torch.multinomial(F.softmax(logits), SAMPLE_K)\n",
        "    # Make sure we didn't predict a repetition and not in NO_TOKENS\n",
        "    pos = torch.nonzero(target_mapping[0][0]).item()\n",
        "    previous_token = input_ids[0][pos-1].item()\n",
        "    next_token = input_ids[0][pos+1].item()\n",
        "    token = None\n",
        "    for i in range(SAMPLE_K):\n",
        "      tok = samples[i].item()\n",
        "      if tok != previous_token and tok != next_token and tok not in XLNET_NO_TOKENS:\n",
        "        # Avoid ALL punctuation\n",
        "        if not is_punctuation(XLNET_TOKENIZER.decode(tok)):\n",
        "          # avoid repeat tokens\n",
        "          word = XLNET_TOKENIZER.decode(tok)\n",
        "          if word.lower() not in XLNET_TOKENIZER.decode(generated_tokens).lower():\n",
        "            token = tok\n",
        "            generated_tokens.append(tok)\n",
        "            break\n",
        "    if token is None:\n",
        "      token = samples[0].item()\n",
        "      generated_tokens.append(token)\n",
        "    # insert the token into the input\n",
        "    input_ids[0][pos] = token\n",
        "    #print(XLNET_TOKENIZER.decode(input_ids[0]))\n",
        "    # Mask out everything that needs to be masked\n",
        "    perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
        "    perm_mask = perm_mask.to('cuda')\n",
        "    masked = input_ids == 6\n",
        "    perm_mask = perm_mask + masked\n",
        "    # Update predicts, should be one less\n",
        "    predicts = torch.nonzero(masked[0]).tolist()\n",
        "    if backward:\n",
        "      predicts = list(reversed(predicts))\n",
        "    # Set up a diagonal where we want to predict, dim=0 is batch, dim=1 is each prediction\n",
        "    target_mapping = torch.zeros((1, len(predicts), input_ids.shape[1]), dtype=torch.float)  \n",
        "    for n, p in enumerate(predicts):\n",
        "      target_mapping[0][n][p] = 1.0\n",
        "    target_mapping = target_mapping.to('cuda')\n",
        "  return XLNET_TOKENIZER.decode(input_ids[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3V-oq679irt",
        "colab_type": "text"
      },
      "source": [
        "Generate a line the ends in a rhyme (XLNET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZz0gibV3F4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_rhyme_line(rhyme, context, target_syllables, terminate_line=True):\n",
        "  good_tries = [] # runs with the exact number of syllables\n",
        "  bad_tries = {}  # Runs with fewer syllables (dict is num_syllables: list of lines)\n",
        "  # i is number of masks\n",
        "  # j is number of tries\n",
        "  for i in range(int(target_syllables*1.5)):\n",
        "    for j in range(NUM_TRIES):\n",
        "      ## Even tries have a period added at the end of the previous context\n",
        "      #if j % 2 == 0 and len(context) > 0 and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
        "      #  context_copy = context[:] + PERIOD\n",
        "      #else:\n",
        "      context_copy = context[:] + BLANK\n",
        "      # This fixes things up\n",
        "      context_copy = XLNET_TOKENIZER.decode(XLNET_TOKENIZER.encode(context_copy, add_special_tokens=False))\n",
        "      # Make masks\n",
        "      prompt = context_copy + BLANK + BLANK.join(['<mask>']*(i+1)) + BLANK + rhyme\n",
        "      if terminate_line or j % 2 == 1:\n",
        "        prompt = prompt + PERIOD\n",
        "      # Fill masks\n",
        "      filled_line = fill_line(prompt, backward=True)\n",
        "      # Figure out how many syllables we added\n",
        "      candidate = remove_prefix(filled_line, context_copy).strip() # the newly added line\n",
        "      line_syllable_count = get_syllables_for_line(candidate) # Number of syllables in newly added line\n",
        "      # Did we get a good run?\n",
        "      if line_syllable_count == target_syllables:\n",
        "        good_tries.append(candidate)\n",
        "        print(\"CANDIDATE\", candidate)\n",
        "      elif line_syllable_count < target_syllables:\n",
        "        # Bad tries are those that are too short. Store in dict by length\n",
        "        if line_syllable_count not in bad_tries:\n",
        "          bad_tries[line_syllable_count] = []\n",
        "        bad_tries[line_syllable_count].append(candidate)\n",
        "  return good_tries, bad_tries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueZ3qzhe9nbG",
        "colab_type": "text"
      },
      "source": [
        "Generate an open-ended line (GPT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS-blkCc4Twh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GPT_NO_TOKENS = [59, 50256, 1, 6, 7, 8, 12, 14, 26, 58, 59, 60, 62, 90, 92, 2503, 3,\n",
        "                 1906, 14988, 26391, 4023, 338] + GPT_NUMBER_TOKENS\n",
        "\n",
        "@use_gpt\n",
        "def generate_non_rhyme_line(context, target_syllables):\n",
        "  generated_tokens = [] # Tokens generated along the way\n",
        "  good_tries = [] # results with the correct number of syllables\n",
        "  past_syllables = get_syllables_for_line(context) # How many syllables in the context\n",
        "  #prep_gpt()\n",
        "  # j is number of tries\n",
        "  for j in range(NUM_TRIES):\n",
        "    new_syllables = 0 # How many new syllables were produced\n",
        "    # Odd tries add a period to the context\n",
        "    #if j % 2 == 0 and len(context) and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
        "    #  context_copy = context[:] + PERIOD\n",
        "    #else:\n",
        "    context_copy = context[:] + BLANK\n",
        "    # Encode the context\n",
        "    generated = GPT_TOKENIZER.encode(context_copy) # Used to collect up tokens\n",
        "    prompt = torch.tensor([generated]) # context put into the right shape\n",
        "    prompt = prompt.to('cuda') if CUDA_AVAILABLE else prompt\n",
        "    past = None # Initially we don't have any history\n",
        "    # Generate until we get enough syllables\n",
        "    previous_token = generated[-1] if len(generated) > 0 else None\n",
        "    count = 0\n",
        "    while new_syllables < target_syllables and count < 1000: # break loop if too many iterations\n",
        "      # Generate\n",
        "      output, new_past = GPT(prompt, past=past)\n",
        "      # Top k filter: there are k real numbers and the rest are -inf\n",
        "      logits = top_k_top_p_filtering(output[0][0], top_k=SAMPLE_K)\n",
        "      tokens = torch.multinomial(F.softmax(logits), SAMPLE_K)\n",
        "      # Pick the first one from the top k that doesn't produce too many syllables\n",
        "      for tok in tokens.tolist():\n",
        "        # How many syllables do we have total?\n",
        "        line_syllables = get_syllables_for_line(GPT_TOKENIZER.decode(generated + [tok]))\n",
        "        # Have we gone over? Or generated a NO_TOKEN?\n",
        "        if line_syllables <= target_syllables + past_syllables and tok not in GPT_NO_TOKENS:\n",
        "          # We are good\n",
        "          word = GPT_TOKENIZER.decode(tok) # The new word\n",
        "          # Don't allow ANY punctuation\n",
        "          if not is_punctuation(word):\n",
        "            if word.lower() not in GPT_TOKENIZER.decode(generated_tokens).lower():\n",
        "              generated_tokens.append(tok)\n",
        "              # Add new word to generated\n",
        "              generated.append(tok) \n",
        "              # Prep for the next run\n",
        "              prompt = torch.tensor([tok]).unsqueeze(0)\n",
        "              prompt = prompt.to('cuda')\n",
        "              past = new_past\n",
        "              new_syllables = line_syllables - past_syllables\n",
        "              break\n",
        "      count = count + 1\n",
        "    candidate = remove_prefix(GPT_TOKENIZER.decode(generated), context).strip()\n",
        "    print(\"CANDIDATE\", candidate)\n",
        "    good_tries.append(candidate)\n",
        "  return good_tries, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f9phyjZfNsv",
        "colab_type": "text"
      },
      "source": [
        "Generate a line that is guaranteed to end in a period (using XLNET)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NgzbyQEMsLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_terminal_non_rhyme_line(context, target_syllables):\n",
        "  good_tries = [] # runs with the exact number of syllables\n",
        "  bad_tries = {}  # Runs with fewer syllables (dict is num_syllables: list of lines)\n",
        "  # i is number of masks\n",
        "  # j is number of tries\n",
        "  for i in range(int(target_syllables*1.5)):\n",
        "    for j in range(NUM_TRIES):\n",
        "      # Even tries have a period added at the end of the previous context\n",
        "      #if j % 2 == 0 and len(context) > 0 and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
        "      #  context_copy = context[:] + PERIOD\n",
        "      #else:\n",
        "      context_copy = context[:] + BLANK\n",
        "      # This fixes things up\n",
        "      context_copy = XLNET_TOKENIZER.decode(XLNET_TOKENIZER.encode(context_copy, add_special_tokens=False))\n",
        "      # Make masks\n",
        "      prompt = context_copy + BLANK + BLANK.join(['<mask>']*(i+1)) + PERIOD # Different from generate_rhyme_line\n",
        "      # Fill masks\n",
        "      filled_line = fill_line(prompt, backward=False) # Forward instead of backward\n",
        "      # Figure out how many syllables we added\n",
        "      candidate = remove_prefix(filled_line, context_copy).strip() # the newly added line\n",
        "      line_syllable_count = get_syllables_for_line(candidate) # Number of syllables in newly added line\n",
        "      # Did we get a good run?\n",
        "      if line_syllable_count == target_syllables:\n",
        "        good_tries.append(candidate)\n",
        "        print(\"CANDIDATE\", candidate)\n",
        "      elif line_syllable_count < target_syllables:\n",
        "        # Bad tries are those that are too short. Store in dict by length\n",
        "        if line_syllable_count not in bad_tries:\n",
        "          bad_tries[line_syllable_count] = []\n",
        "        bad_tries[line_syllable_count].append(candidate)\n",
        "  return good_tries, bad_tries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZiO7py_z6g",
        "colab_type": "text"
      },
      "source": [
        "##Main execution loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkFtgmOyztGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(context, scheme, rhyme_dict, use_near_rhymes = False, post = None, \n",
        "        recontextualize = False, interactive = False):\n",
        "  ### SETUP #####################################\n",
        "  lines = []    # Store the lyrics lines\n",
        "  segments = [] # Store each segment separately\n",
        "  # Set up the context\n",
        "  context = context[:].strip()\n",
        "  original_context = context[:]\n",
        "  # Set up rhyme history\n",
        "  rhyme_history = [] # The history of words used for rhymes\n",
        "  # original context shouldn't have punctuation at the end, but the first prompt to the neural net should\n",
        "  if len(context) >0 and context[-1] not in PUNCTUATION:\n",
        "    context = context + PERIOD\n",
        "  if len(original_context) > 0 and original_context[-1] in PUNCTUATION:\n",
        "    original_context = original_context[:-1]\n",
        "  # copy the rhyme_dict because we will be adding to it\n",
        "  rhyme_dict = copy.deepcopy(rhyme_dict)\n",
        "  ### ITERATE THROUGH SCHEME #####################\n",
        "  # An entry can be tuples or lists of tuples. \n",
        "  # Easiest thing is to nest tuples into lists and treat everything the same\n",
        "  for n, entry in enumerate(scheme):\n",
        "    ### RECONTEXTUALIZE ##########################\n",
        "    # Insert the original context into the history/context at sentence breaks\n",
        "    if n > 0 and recontextualize:\n",
        "      last_period = context.rfind(PERIOD)\n",
        "      last_contextualization = context.rfind(original_context)\n",
        "      if last_period >= 0 and last_contextualization >= 0 and last_contextualization + len(original_context) - 1 != last_period - 1:\n",
        "        context = merge_lines(merge_lines(context[:last_period+1], original_context, force_break=True), context[last_period+1:], force_break=True)\n",
        "    ### ITERATE THROUGH LINE SPEC #################\n",
        "    current_line = []   # The line currently being worked on. May be made of several segments\n",
        "    # if line is a single segment, nest it\n",
        "    if isinstance(entry, tuple):\n",
        "      entry = [entry]\n",
        "    # A line has 1 or more tuples of the form (target_syllables, rhyme_index)\n",
        "    for segment_num, segment in enumerate(entry):\n",
        "      is_end_segment = (segment_num == len(entry) - 1)\n",
        "      target_syllables = segment[0]\n",
        "      rhyme_idx = segment[1]\n",
        "      cmd = None\n",
        "      goods = []    # lines with the right number of syllables\n",
        "      shorts = {}   # lines with too few syllables\n",
        "      new_context = None # The complete lyrics after a new line is added\n",
        "      new_syllables = 0 # The number of new syllables added to lyrics\n",
        "      terminate_segment = False\n",
        "      ### PARSE SPECIAL COMMANDS ##################\n",
        "      # We have commands to parse\n",
        "      if len(segment) > 2:\n",
        "        cmd = segment[2]\n",
        "        terminate_segment = (cmd == ':end')\n",
        "      print(\"LINE\", n, \"SEGMENT\", segment_num, '(end)' if is_end_segment else '', \"TARGET SYLLABLES\", target_syllables, \"RHYME INDEX\", rhyme_idx, \"COMMAND\", cmd)\n",
        "      # Check if we are filling in a partial line (when there is a rhyme or when there is a given verbatim string)\n",
        "      if isinstance(rhyme_idx, str) or rhyme_idx in rhyme_dict:\n",
        "        ### USE RHYME INDEX ########################\n",
        "        # We are filling a line\n",
        "        end_targets = [] # The line should end in this word (or words)\n",
        "        ### RHYME INDEX IS A STRING ####\n",
        "        if isinstance(rhyme_idx, str):\n",
        "          # Use a verbatim string\n",
        "          end_targets = [rhyme_idx] # rhyme_idx is actually a string\n",
        "          # If target_syllables < 0 then set it to the exact number of syllables in the rhyme_idx string\n",
        "          if target_syllables < 0:\n",
        "            target_syllables = get_syllables_for_line(rhyme_idx)\n",
        "        ### PICK A RHYME WORD ####\n",
        "        else:\n",
        "          # Get some rhyming words\n",
        "          # but first fix the dictionary if there is a single word instead of a list\n",
        "          if not isinstance(rhyme_dict[rhyme_idx], list) and not isinstance(rhyme_dict[rhyme_idx], tuple):\n",
        "            rhyme_dict[rhyme_idx] = [rhyme_dict[rhyme_idx]]\n",
        "          # Now get some words\n",
        "          if rhyme_idx not in rhyme_dict:\n",
        "            pdb.set_trace()\n",
        "          end_targets = [pick_rhyme(w, perfect=not use_near_rhymes, context=context, history=rhyme_history) for w in rhyme_dict[rhyme_idx]]\n",
        "        # There could be more than one possible rhyme target\n",
        "        ### GENERATE #####\n",
        "        for end_target in end_targets:\n",
        "          print(\"RHYME TARGET\", end_target)\n",
        "          # Check to see if the end_target already fills up all of our syllable length\n",
        "          end_target_syllables = get_syllables_for_line(end_target)\n",
        "          if end_target_syllables < target_syllables:\n",
        "            # Generate new lines\n",
        "            meet_target_syllables, too_short = generate_rhyme_line(end_target, context, target_syllables, terminate_line=terminate_segment)\n",
        "            goods = goods + meet_target_syllables\n",
        "            shorts = merge_dicts(shorts, too_short)\n",
        "          else:\n",
        "            # Just copy the end target because that is all the syllables we need\n",
        "            goods.append(end_target)\n",
        "      else:\n",
        "        ### NON-RHYME SEGMENT ###############################\n",
        "        # We are generating a new line unconstrained\n",
        "        # Generate new line\n",
        "        if terminate_segment:\n",
        "          # We've determined this segment must be terminal.\n",
        "          match_target_syllables1, shorts = generate_terminal_non_rhyme_line(context, target_syllables)\n",
        "          goods = match_target_syllables1\n",
        "        else:\n",
        "          # Segment does not need to be terminal\n",
        "          match_target_syllables1, _ = generate_non_rhyme_line(context, target_syllables)\n",
        "          match_target_syllables2 =  []\n",
        "          if is_end_segment:\n",
        "            match_target_syllables2, shorts = generate_terminal_non_rhyme_line(context, target_syllables)\n",
        "          goods = match_target_syllables1 + match_target_syllables2\n",
        "      ### PICK BEST CANDIDATE ############################################\n",
        "      results = []\n",
        "      if len(goods) > 0:\n",
        "        results = goods\n",
        "      else:\n",
        "        longest_key = max(list(shorts.keys()))\n",
        "        results = shorts[longest_key]\n",
        "      best_continuation, score = pick_best_line(results, context, history=segments, interactive=interactive)\n",
        "      new_syllables = get_syllables_for_line(best_continuation)\n",
        "      ### UPDATE RHYME DICTIONARY AND RHYME HISTORY ####################################\n",
        "      # If we are using near rhymes, store the near rhyme as possible target for future lines\n",
        "      if not isinstance(rhyme_idx, str) and rhyme_idx >=0:\n",
        "        # Make a new entry in rhyme_dict\n",
        "        if (rhyme_idx not in rhyme_dict) or (rhyme_idx in rhyme_dict and use_near_rhymes):\n",
        "          continuation = ''.join(list(filter(lambda c: c in STR_LETTERS or c == BLANK, best_continuation)))\n",
        "          split_continuation = continuation.split(BLANK)\n",
        "          end_word = split_continuation[-1]\n",
        "          if end_word[-1] in PUNCTUATION:\n",
        "            end_word = end_word[:-1]\n",
        "          if rhyme_idx not in rhyme_dict:\n",
        "            rhyme_dict[rhyme_idx] = []\n",
        "          rhyme_dict[rhyme_idx].append(end_word)\n",
        "        # Add to rhyme history\n",
        "        rhyme_history.append(end_word)\n",
        "      ### DO SOME FIXING #################################################\n",
        "      # Fill in if we don't have enough syllables\n",
        "      if new_syllables < target_syllables:\n",
        "        rest = add_filler(best_continuation, target_syllables - new_syllables, 0)\n",
        "      ### SET UP CONTEXT FOR NEXT ITERATION ##########################\n",
        "      context = merge_lines(context, best_continuation)\n",
        "      print('CONTEXT', context)\n",
        "      current_line.append(best_continuation)\n",
        "      segments.append(best_continuation)\n",
        "      # get ready for the next iteration\n",
        "      context = crop_line(context)\n",
        "      previous_is_end_segment = is_end_segment\n",
        "    ### DONE WITH LINE #################################################\n",
        "    # put the current line together\n",
        "    lines.append(BLANK.join(fix_final_lines_punctuation(current_line)))\n",
        "  ### DONE WITH SPEC ###################################################\n",
        "  #lines = fix_final_lines_punctuation(lines)\n",
        "  lines = post_process_lines(lines, post)\n",
        "  lines = fix_final_lines_capitalization(lines)\n",
        "  return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I3FhY_h1RL0",
        "colab_type": "text"
      },
      "source": [
        "## GUI Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEmJVcpX1WeY",
        "colab_type": "text"
      },
      "source": [
        "Extract the syllable and rhyme scheme from given lyrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMMAjAAs1Sw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_scheme(lines, use_near_rhymes = True):\n",
        "  syllables = []\n",
        "  ends = []\n",
        "  rhyme_lines = {}\n",
        "  # Compute syllables per line\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    num_syl = get_syllables_for_line(line)\n",
        "    syllables.append(num_syl)\n",
        "    ends.append(line[-1] == '.')\n",
        "  # Figure out which lines rhyme, piecewise\n",
        "  for i, line1 in enumerate(lines):\n",
        "    line1 = line1.strip()\n",
        "    words1 = line1.split()\n",
        "    last1 = words1[-1]\n",
        "    for j, line2 in enumerate(lines):\n",
        "      if i != j:\n",
        "        line2 = line2.strip()\n",
        "        words2 = line2.split()\n",
        "        last2 = words2[-1]\n",
        "        if perfect_rhyme(last1, last2) or (use_near_rhymes and near_rhyme(last1, last2)):\n",
        "          if i not in rhyme_lines:\n",
        "            rhyme_lines[i] = []\n",
        "          if j not in rhyme_lines:\n",
        "            rhyme_lines[j] = []\n",
        "          if j not in rhyme_lines[i]:\n",
        "            rhyme_lines[i].append(j)\n",
        "          if i not in rhyme_lines[j]:\n",
        "            rhyme_lines[j].append(i)\n",
        "  # Gather up all rhyming lines\n",
        "  for l1 in list(rhyme_lines.keys()):\n",
        "    for l2 in rhyme_lines[l1]:\n",
        "      for l3 in list(rhyme_lines[l2]):\n",
        "        if l3 not in rhyme_lines[l1]:\n",
        "          rhyme_lines[l1].append(l3)\n",
        "  # reduce to unique sets\n",
        "  rhyme_sets = []\n",
        "  for l in list(rhyme_lines.values()):\n",
        "    rhyme_set = set(l)\n",
        "    if rhyme_set not in rhyme_sets:\n",
        "      rhyme_sets.append(rhyme_set) \n",
        "  # Assign rhyme indexes to lines\n",
        "  rhyme_idxs = {}\n",
        "  for n, s in enumerate(rhyme_sets):\n",
        "    for l in s:\n",
        "      rhyme_idxs[l] = n\n",
        "  # Build schema\n",
        "  schema = []\n",
        "  for n in range(len(lines)):\n",
        "    segment = None\n",
        "    syl_num = syllables[n]\n",
        "    rhyme_idx = rhyme_idxs[n] if n in rhyme_idxs else -1\n",
        "    if ends[n]:\n",
        "      segment = (syl_num, rhyme_idx, ':end')\n",
        "    else:\n",
        "      segment = (syl_num, rhyme_idx)\n",
        "    schema.append(segment)\n",
        "  return schema"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x8OYI9S1bcn",
        "colab_type": "text"
      },
      "source": [
        "Callback hooks from javascript/html."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i9UMh_m1do7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def python_run_hook(prompt, text, use_near_rhymes = False, recontextualize = False):\n",
        "  text = text.strip()\n",
        "  lines = text.split('\\n')\n",
        "  prompt = prompt.strip()\n",
        "  scheme = None\n",
        "  try:\n",
        "    if text[0] == '[':\n",
        "      scheme = eval(text)\n",
        "    else:\n",
        "      scheme = extract_scheme(lines, use_near_rhymes)\n",
        "    print(scheme)\n",
        "    lines = run(prompt, scheme, {}, recontextualize=recontextualize, use_near_rhymes=use_near_rhymes, post=[])\n",
        "    pretty_print(lines)\n",
        "    return IPython.display.JSON({'result': 'true'})\n",
        "  except:\n",
        "    return IPython.display.JSON({'result': 'false'})\n",
        "\n",
        "\n",
        "output.register_callback('notebook.python_run_hook', python_run_hook)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk7rxv50APc",
        "colab_type": "text"
      },
      "source": [
        "# GUI\n",
        "\n",
        "You can launch the system by entering \n",
        "\n",
        "- Context, a short phrase about the topic of the lyrics.\n",
        "- The lyrics from an existing song with carriage returns at the end of each line. If a line has a period at the end, the system will honor it. Lines without periods may or may not get sentence breaks.\n",
        "\n",
        "The system will reverse engineer the syllable pattern and the rhyme scheme (only looking for the last words of each line).\n",
        "\n",
        "You can choose whether to use near rhymes (if unchecked, the system will only use perfect rhymes).\n",
        "\n",
        "You an choose to recontextualize. The system will attempt to reintroduce the context phrase throughout to keep the lyrics on topic. No guarantees.\n",
        "\n",
        "How to use:\n",
        "\n",
        "1. From the menu at the top, select Runtime >> Run all\n",
        "2. Scroll down below this cell to enter lyrics and context prompt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_k0TBRv0akQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "7da02951-873c-4209-9987-76b90aea7ee9"
      },
      "source": [
        "%%html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\n",
        "\n",
        "<style>\n",
        "// MAKE CANVAS \n",
        "canvas {\n",
        "    border:1px solid #d3d3d3;\n",
        "    background-color: #f1f1f1;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "<script>\n",
        "function js_run() {\n",
        "  var the_text = \"\";\n",
        "  var prompt = \"\";\n",
        "  var recontextualize = false;\n",
        "  var use_near_rhymes = false;\n",
        "  var input_lyrics = document.getElementById(\"inp_lyrics\");\n",
        "  var input_prompt = document.getElementById(\"inp_prompt\");\n",
        "  var input_recontextualize = document.getElementById(\"inp_recontextualize\");\n",
        "  var input_near_rhymes = document.getElementById(\"inp_near_rhymes\");\n",
        "  if (input_lyrics.value.length == 0) {\n",
        "    return;\n",
        "  }\n",
        "  if (input_prompt.value.length == 0) {\n",
        "    return;\n",
        "  }\n",
        "  recontextualize = input_recontextualize.checked;\n",
        "  use_near_rhymes = input_near_rhymes.checked;\n",
        "  the_text = input_lyrics.value;\n",
        "  prompt = input_prompt.value;\n",
        "  // Call python\n",
        "  (async function() {\n",
        "    const result = await google.colab.kernel.invokeFunction(\n",
        "      'notebook.python_run_hook', // The callback name.\n",
        "      [prompt, the_text, use_near_rhymes, recontextualize], // The arguments.\n",
        "      {}); // kwargs\n",
        "    const res = result.data['application/json'];\n",
        "    //document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
        "  })();\n",
        "}\n",
        "</script>\n",
        "<strong>Context prompt:</strong> <input id=\"inp_prompt\" /><br>\n",
        "<strong>Enter lyrics here:</strong><br />\n",
        "<textarea rows = \"5\" cols = \"60\" name = \"description\" id=\"inp_lyrics\">\n",
        "</textarea><br />\n",
        "<strong>Recontextualize?</strong> <input type=\"checkbox\" id=\"inp_recontextualize\" /><br />\n",
        "<strong>Use near rymes?</strong> <input type=\"checkbox\" id=\"inp_near_rhymes\" /><br />\n",
        "<button onmouseup=\"js_run()\">Run!</button><br>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\n",
              "\n",
              "<style>\n",
              "// MAKE CANVAS \n",
              "canvas {\n",
              "    border:1px solid #d3d3d3;\n",
              "    background-color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "</head>\n",
              "<body>\n",
              "<script>\n",
              "function js_run() {\n",
              "  var the_text = \"\";\n",
              "  var prompt = \"\";\n",
              "  var recontextualize = false;\n",
              "  var use_near_rhymes = false;\n",
              "  var input_lyrics = document.getElementById(\"inp_lyrics\");\n",
              "  var input_prompt = document.getElementById(\"inp_prompt\");\n",
              "  var input_recontextualize = document.getElementById(\"inp_recontextualize\");\n",
              "  var input_near_rhymes = document.getElementById(\"inp_near_rhymes\");\n",
              "  if (input_lyrics.value.length == 0) {\n",
              "    return;\n",
              "  }\n",
              "  if (input_prompt.value.length == 0) {\n",
              "    return;\n",
              "  }\n",
              "  recontextualize = input_recontextualize.checked;\n",
              "  use_near_rhymes = input_near_rhymes.checked;\n",
              "  the_text = input_lyrics.value;\n",
              "  prompt = input_prompt.value;\n",
              "  // Call python\n",
              "  (async function() {\n",
              "    const result = await google.colab.kernel.invokeFunction(\n",
              "      'notebook.python_run_hook', // The callback name.\n",
              "      [prompt, the_text, use_near_rhymes, recontextualize], // The arguments.\n",
              "      {}); // kwargs\n",
              "    const res = result.data['application/json'];\n",
              "    //document.querySelector(\"#output-area\").appendChild(document.createTextNode(text.result));\n",
              "  })();\n",
              "}\n",
              "</script>\n",
              "<strong>Context prompt:</strong> <input id=\"inp_prompt\" /><br>\n",
              "<strong>Enter lyrics here:</strong><br />\n",
              "<textarea rows = \"5\" cols = \"60\" name = \"description\" id=\"inp_lyrics\">\n",
              "</textarea><br />\n",
              "<strong>Recontextualize?</strong> <input type=\"checkbox\" id=\"inp_recontextualize\" /><br />\n",
              "<strong>Use near rymes?</strong> <input type=\"checkbox\" id=\"inp_near_rhymes\" /><br />\n",
              "<button onmouseup=\"js_run()\">Run!</button><br>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ76XNmGziTT",
        "colab_type": "text"
      },
      "source": [
        "# Advanced User Mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EL6v5mdGZ-t",
        "colab_type": "text"
      },
      "source": [
        "## Rhyme Scheme\n",
        "\n",
        "A scheme indicates how many lines, how many syllables per line, and which lines rhyme with each other.\n",
        "\n",
        "A scheme is a list of tuples where each tuple is the number of syllables in a segment and an index (number)\n",
        "indicating which other segments to rhyme with.\n",
        "For example ```[(5, 1), (6, 2), (7, 1), (8, 2)]``` would indicate four segments, where the first and third segments rhyme. The first segment has five syllables, the second segment has six syllables, and so on.\n",
        "\n",
        "Instead of a rhyme index, you can also provide a word or phrase that the segment should end with.\n",
        "The number of syllables for that segments should be greater than or equal to the number of syllables\n",
        "in the word or phrase. For example, ```[(5, 1), (6, 1), (7, 'dead')]``` would make sure the last word of the last\n",
        "segment ended in the word ```'dead'```. \n",
        "Likewise ```[(3, 'hello world'), (6, 1), (7, 1)]``` would start with the entire first \n",
        "segment being 'hello world'. \n",
        "\n",
        "For most situations, a segment would correspond to a complete line on lyrics. But in some cases you want multiple segments per line, so as to have rhymes within a line. In this case, you can wrap tuples in a list, such as ```[(6, 1), [(4, 2), (4, 2), (4, 1)], (7, 1)]```, which would have three lines consisting of 6 syllables, 4+4+4=12 syllables, and 7 syllables, respectively. Each line would end in a rhyming word, but the second line would have two words that rhyme in the middle.\n",
        "\n",
        "The rhyme index is looked up in the rhyme dictionary for the song (```rhyme_dict```). This is not the *near rhyme dictionary* which is a list of all words known to nearly rhyme. The rhyme dictionary for the song is a list of words that the system should try to rhyme with when it gets to the end of a segment. If there is no entry in the dictionary, the system will generate forward unconstrained the appropriate number of syllables and the last word will be added to the ```rhyme_dict```. If the rhyme index is in the dictionary, then the system will pick a word that rhymes to end the segment in. If near rhyming is used, then near rhymes are added to the dictionary.In the ```rhyme_dict``` each rhyme index is associated with a list of words to rhyme with.\n",
        "\n",
        "The number of syllables for a segment can be indicated with ```-1``` if the rhyme index for the segment has been replaced by a string. The ```-1``` tells the system to use however many syllables are in the string.\n",
        "\n",
        "If the rhyme index for a segment is given as ```-1``` this tells the system to not try to rhyme with this segment.\n",
        "\n",
        "A segment can take a third parameter, special instructions on how to handle the segment, ```(syllables, rhyme_index, command)```. Currently the only command is ```\":end\"``` which tells the system that this segement should end in a period. \n",
        "\n",
        "There is a post-processing step to add text to the beginning or ending of lines. It is useful for \"ooh\"s and other things that one might not want the neural language models to pick up on and include in the generation if they are given instead of rhyme indices. Post-processing is specified with a special dictionary (```post```) where each key is a number indicating the line number to be post-processed. The value is a tuple ```(pre, post)``` where ```pre``` is a string to add to the beginning of the line and ```post``` is a string to add to the end of the line. Either can be ```None```.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ4boOSXGX6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rhyme_dict = {}   # Rhyming lines are indicated by number. What word should certain lines rhyme with?\n",
        "post = {}         # Post-processing scheme\n",
        "\n",
        "# BEAT IT, MICHAEL JACKSON\n",
        "scheme = [\n",
        "#They told him don't you ever come around here\n",
        "          (11, 1), #0\n",
        "#Don't want to see your face, you better disappear\n",
        "          [(6, -1), (6, 1)], #1\n",
        "#The fire's in their eyes and their words are really clear\n",
        "          [(5, -1), (7, 1)], #2\n",
        "#So beat it, just beat it\n",
        "          (3, 2, ':end'), #3\n",
        "#You better run, you better do what you can\n",
        "          (11, 3), #4\n",
        "#Don't want to see no blood, don't be a macho man\n",
        "          [(6, -1), (6, 3)], #5\n",
        "#You want to be tough, better do what you can\n",
        "          [(5, -1), (6, 3)], #6\n",
        "#So beat it, but you want to be bad\n",
        "          [(3, 2), (6, -1)], #7\n",
        "#Just beat it, beat it, beat it, beat it\n",
        "          (3, 2, ':end'), #8\n",
        "#No one wants to be defeated\n",
        "          (8, 2), #9\n",
        "#Showin' how funky and strong is your fight\n",
        "          (10, 4), #10\n",
        "#It doesn't matter who's wrong or right\n",
        "          (9, 4), #11\n",
        "#Just beat it, beat it\n",
        "          (3, 2), #12\n",
        "#Just beat it, beat it\n",
        "          (3, 2), #13\n",
        "#Just beat it, beat it\n",
        "          (3, 2), #14\n",
        "#Just beat it, beat it\n",
        "          (3, 2, ':end') #15\n",
        "]\n",
        "#rhyme_dict[1] = ['here']\n",
        "post[3] = (None, ' just {repeat 2}.')\n",
        "post[8] = (None, ' ({repeat 2}), {repeat 2}, ({repeat 2})')\n",
        "post[12] = (None, ' ({repeat 2})')\n",
        "post[13] = (None, ' ({repeat 2})')\n",
        "post[14] = (None, ' ({repeat 2})')\n",
        "post[15] = (None, ' ({repeat 2}), oooooh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-OHTh5nvfcZ",
        "colab_type": "text"
      },
      "source": [
        "## Run!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkgzP3nivio1",
        "colab_type": "text"
      },
      "source": [
        "Set the context to bias the agent toward a particular topic or theme. This will be added to the beginning of the lyrics as hidden text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTTJMk1pMncs",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "context = \"My favorite food is tacos\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4AGPk57GjBv",
        "colab_type": "text"
      },
      "source": [
        "**Run the generator.**\n",
        "\n",
        "Set ```use_near_rhymes=True``` to use near rhymes or set to ```False``` to use perfect rhymes.\n",
        "\n",
        "Set ```recontextualize=True``` to try to force the generator to attend to the original context more often. This causes the original context to be added after every sentence break to try to steer the generators back to the context. It won't show up in the final output.\n",
        "\n",
        "Set ```interactive=True``` to manually select candidates for each segment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0InlSRUVEoIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RUN_ADVANCED_MODE = False #@param {type:\"boolean\"}\n",
        "use_near_rhymes = True #@param {type:\"boolean\"}\n",
        "recontextualize = False #@param {type:\"boolean\"}\n",
        "interactive = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Run the generator\n",
        "if RUN_ADVANCED_MODE:\n",
        "  lines = run(context, scheme, rhyme_dict, \n",
        "              use_near_rhymes=use_near_rhymes, \n",
        "              post=post, \n",
        "              recontextualize=recontextualize, \n",
        "              interactive=interactive)\n",
        "  # Print the outcome\n",
        "  pretty_print(lines)\n",
        "  # Save the phonentics cache\n",
        "  save_phone_cache(PHONE_CACHE, PHONE_CACHE_PATH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGQ_wrxeZ2sr",
        "colab_type": "text"
      },
      "source": [
        "# Generate Karaoke Video\n",
        "\n",
        "To do this you need an mp3 or mp4 file of music without vocals. A good way to do this is to find an existing karaoke video on YouTube. \n",
        "\n",
        "You will also need to know how many seconds each line of lyrics takes, down to at least the tenth of a second (but probably down to a millisecond to get the timing aligned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDpxL_XpKCiD",
        "colab_type": "text"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HuCnyaOVf7O",
        "colab_type": "code",
        "outputId": "caaa9cd1-be43-4a8d-90a2-8abeab006921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install pytube3"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytube3\n",
            "  Downloading https://files.pythonhosted.org/packages/de/86/198092763646eac7abd2063192ab44ea44ad8fd6d6f3ad8586b38afcd52a/pytube3-9.6.4-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from pytube3) (3.6.6)\n",
            "Installing collected packages: pytube3\n",
            "Successfully installed pytube3-9.6.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMK0vlWWZ5XB",
        "colab_type": "code",
        "outputId": "f52c13c0-dcdf-48ef-e16a-9a2e6d96d151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import moviepy.editor as mpe\n",
        "from pytube import YouTube"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1515520/45929032 bytes (3.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4497408/45929032 bytes (9.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8306688/45929032 bytes (18.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12189696/45929032 bytes (26.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16089088/45929032 bytes (35.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19767296/45929032 bytes (43.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23527424/45929032 bytes (51.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27312128/45929032 bytes (59.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31162368/45929032 bytes (67.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34938880/45929032 bytes (76.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37396480/45929032 bytes (81.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41222144/45929032 bytes (89.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45096960/45929032 bytes (98.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfTgvG7cRuDe",
        "colab_type": "text"
      },
      "source": [
        "## Video Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Hh19RMKN6r",
        "colab_type": "text"
      },
      "source": [
        "Need to set the font"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU6wKOZeKSwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a list of fonts available on the OS\n",
        "#!fc-list\n",
        "# Set the font\n",
        "FONT = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", size=24)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ohyA9NKj_O",
        "colab_type": "text"
      },
      "source": [
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2iVw5Z5KfTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT_OFFSET = (10, 10)\n",
        "EPSILON = 0.01\n",
        "\n",
        "def secs_to_millis(secs):\n",
        "  return secs*1000\n",
        "\n",
        "def convert(gif, mp4):\n",
        "    os.system(\"ffmpeg -f gif -i \" + gif + \" \" + mp4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsO_YvqPVXDy",
        "colab_type": "text"
      },
      "source": [
        "Download from YouTube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duJpnwdbVZcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REMOVE_FROM_FILENAME = ['.', ',', '*']\n",
        "\n",
        "def download_youtube(url):\n",
        "  yt = YouTube(url)\n",
        "  title = yt.title\n",
        "  stream = yt.streams.filter(file_extension='mp4').first() #only_audio=True\n",
        "  stream.download()\n",
        "  return ''.join(c for c in title if not c in REMOVE_FROM_FILENAME) + '.mp4' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnNzezimKl7Q",
        "colab_type": "text"
      },
      "source": [
        "Frame creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V268y6b5KlO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def create_frame(lines, highlight, fnt, background = \"black\", text_color = 'white', highlight_color = 'yellow', frame_wh = (1024, 768), text_offset_xy = (0, 0)):\n",
        "    text_x, text_y = text_offset_xy\n",
        "    spacing = frame_wh[1] / len(lines)\n",
        "    img = Image.new('RGB', frame_wh, background)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # draw.ellipse takes a 4-tuple (x0, y0, x1, y1) where (x0, y0) is the top-left bound of the box\n",
        "    # and (x1, y1) is the lower-right bound of the box.\n",
        "    for i, line in enumerate(lines):\n",
        "      color = text_color if i != highlight else highlight_color\n",
        "      draw.text((text_x, text_y + (i * spacing)), line, font = fnt, fill=color)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QMwILfjR7KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_video_by_durations(filename, audio_file_or_youtube, \n",
        "                            lines, start_time, durations, \n",
        "                            music_artist, music_title, attribution = 'Weird A.I. Yankovic', \n",
        "                            new_title = None,\n",
        "                            frame_wh = (1024, 768),\n",
        "                            for_twitter = False):\n",
        "  # Copy durations\n",
        "  durations = list(map(lambda x:secs_to_millis(x), [start_time] + durations))\n",
        "  frames = []\n",
        "\n",
        "  # Make a title if none given\n",
        "  if new_title is None:\n",
        "    init_line = lines[0].split()\n",
        "    new_title = BLANK.join(init_line[0:min(4, len(init_line))])\n",
        "\n",
        "  # Make title frame\n",
        "  music_by = 'Music by: ' + music_artist + ' (\"' + music_title + '\")'\n",
        "  lyrics_by = 'Lyrics by: ' + attribution\n",
        "  title_lines = [new_title, music_by, lyrics_by]\n",
        "  temp_file_gif = filename + '.TEMP_GIF.gif'\n",
        "  temp_file_mp4 = filename + '.TEMP_VIDEO_MP4.mp4'\n",
        "  title_frame = create_frame(title_lines, 0, FONT, frame_wh=frame_wh, text_offset_xy=TEXT_OFFSET)\n",
        "  frames.append(title_frame)\n",
        "\n",
        "  # If we can, get the lyrics up early\n",
        "  if start_time > 5.0:\n",
        "    title_duration = 5.0\n",
        "    interstitial_duration = start_time - 5.0\n",
        "    if start_time > 10.0:\n",
        "      title_duration = 10.0\n",
        "      interstitial_duration = start_time - 5.0\n",
        "    durations = [secs_to_millis(title_duration), secs_to_millis(interstitial_duration)] + durations[1:]\n",
        "    preview_frame = create_frame(lines, -1, FONT, frame_wh=frame_wh, text_offset_xy=TEXT_OFFSET)\n",
        "    frames.append(preview_frame)\n",
        "\n",
        "  # Make rest of frames\n",
        "  for i, line in enumerate(lines):\n",
        "      new_frame = create_frame(lines, i, FONT, frame_wh=frame_wh, text_offset_xy=TEXT_OFFSET)\n",
        "      frames.append(new_frame)\n",
        "\n",
        "  # End lyrics frame\n",
        "  durations.append(secs_to_millis(EPSILON))\n",
        "  end_frame = create_frame(lines, -1, FONT, frame_wh=frame_wh, text_offset_xy=TEXT_OFFSET)\n",
        "  frames.append(end_frame)\n",
        "\n",
        "  # Save into a GIF file \n",
        "  frames[0].save(temp_file_gif, format='GIF',\n",
        "                append_images=frames[1:], save_all=True, duration=durations)\n",
        "  # Convert to MP4\n",
        "  convert(temp_file_gif, temp_file_mp4)\n",
        "  # Load mp4\n",
        "  my_clip = mpe.VideoFileClip(temp_file_mp4)\n",
        "  # Load audio (mp3 or mp4)\n",
        "  audio_file = audio_file_or_youtube\n",
        "  if 'https://www.youtube.com' in audio_file_or_youtube or 'https://youtu' in audio_file_or_youtube:\n",
        "    audio_file = download_youtube(audio_file_or_youtube)\n",
        "  # Sometimes there are naming problems with the youtube download\n",
        "  while not os.path.exists(audio_file):\n",
        "    audio_file = input(\"File not found. Please enter the name of the file: \")\n",
        "  # Get audio\n",
        "  audio_clip = mpe.AudioFileClip(audio_file)\n",
        "  # For Twitter\n",
        "  if for_twitter:\n",
        "    audio_clip = audio_clip.subclip(0, 120)\n",
        "  # Add audio to video\n",
        "  my_clip = my_clip.set_audio(audio_clip)\n",
        "  # Write mp4\n",
        "  my_clip.write_videofile(filename, \n",
        "                        audio=True,\n",
        "                        codec='libx264', \n",
        "                        audio_codec='aac', \n",
        "                        temp_audiofile='temp_audio.m4a', ) # default codec: 'libx264', 24 fps\n",
        "  # Clean up\n",
        "  os.remove(temp_file_gif)\n",
        "  os.remove(temp_file_mp4)\n",
        "\n",
        "def make_video_by_line_timing(filename, audio_file_or_youtube, \n",
        "                              lines, timing, total_duration, \n",
        "                              music_artist, music_title, attribution = 'Weird A.I. Yankovic',\n",
        "                              new_title = None, \n",
        "                              frame_wh = (1024, 768),\n",
        "                              for_twitter = False):\n",
        "  counter = timing[0]\n",
        "  durations = [counter]\n",
        "  for time in timing[1:]:\n",
        "    dur = time - counter\n",
        "    durations.append(dur)\n",
        "    counter = time\n",
        "  durations.append(total_duration - counter)\n",
        "  make_video_by_durations(filename, audio_file_or_youtube, lines, durations[0], durations[1:], music_artist, music_title, attribution, new_title, frame_wh, for_twitter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22iCwUrzR88y",
        "colab_type": "text"
      },
      "source": [
        "## Run the Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y28iGiatKyrm",
        "colab_type": "text"
      },
      "source": [
        "There are two ways to make the clip. \n",
        "\n",
        "1. If you know the duration of each line of lyrics, use ```make_video_by_durations()```. You will also need to set the start time of the first line so that lyrics match the music.\n",
        "\n",
        "2. If you know the start time of each line, use ```make_video_by_line_timing()```. You will also need to know the total duration of the lyrics.\n",
        "\n",
        "If you want a video that you can post to Twitter, it must be less than 2 minutes; setting ```for_twitter=True``` will clip the video. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4qCoETNKtSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BEAT IT, MICHAEL JACKSON\n",
        "# Timing works for https://www.youtube.com/watch?v=cuSi8yR9rKk\n",
        "start_time = 43.2\n",
        "line_durations = [3.0, 3.3, 3.4, 4.2, 2.8, 3.6, 3.3, 3.5, 3.7, 3.5, 3.4, 3.3, 1.9, 1.9, 1.4, 2.3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iudqml6QOobE",
        "colab_type": "text"
      },
      "source": [
        "To run the karaoke video generation, set ```MAKE_KARAOKE_VIDEO=True``` and fill in the required values using the form to the right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdjlmp85MtL6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "MAKE_KARAOKE_VIDEO = False #@param{type:\"boolean\"}\n",
        "save_filename = 'my_karaoke.mp4' #@param {type:\"string\"}\n",
        "title = 'Sassafras' #@param {type:\"string\"}\n",
        "audio_file_or_youtube = 'https://www.youtube.com/watch?v=cuSi8yR9rKk' #@param {type:\"string\"}\n",
        "music_artist = 'Michael Jackson' #@param {type:\"string\"}\n",
        "original_music_title = 'Beat It' #@param {type:\"string\"}\n",
        "attribution = 'Weird A.I. Yankovic and its user' #@param {type:\"string\"}\n",
        "for_twitter = True #@param {type:\"boolean\"}\n",
        "\n",
        "if MAKE_KARAOKE_VIDEO: \n",
        "  make_video_by_durations(save_filename, audio_file_or_youtube, \n",
        "                          lines, start_time, line_durations, \n",
        "                          music_artist, original_music_title, \n",
        "                          new_title=title,\n",
        "                          attribution=attribution,\n",
        "                          for_twitter=for_twitter) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQVTdSuXCOcq",
        "colab_type": "text"
      },
      "source": [
        "# License\n",
        "\n",
        "Copyright 2020 Mark Owen Riedl\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    }
  ]
}